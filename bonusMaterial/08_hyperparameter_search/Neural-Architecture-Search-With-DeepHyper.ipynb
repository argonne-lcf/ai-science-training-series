{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af205a35",
   "metadata": {
    "id": "af205a35"
   },
   "source": [
    "# Neural Architecture Search (Basic)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deephyper/tutorials/blob/main/tutorials/colab/NAS_basic.ipynb)\n",
    "\n",
    "In this tutorial we will learn the basics of neural architecture search (NAS). We will use artificial data generated from a polynomial function. Then, we will discover how to create a search space of neural architecture using a directed graph. Finally, we will see how to define the NAS settings and how to execute the search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "klX2lZZ-FV0Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "klX2lZZ-FV0Y",
    "outputId": "bdfa3afc-d299-4424-fd87-cf7517a0c487"
   },
   "outputs": [],
   "source": [
    "!pip install deephyper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t89JAGGwFWhM",
   "metadata": {
    "id": "t89JAGGwFWhM"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Warning</b>\n",
    "    \n",
    "By design asyncio does not allow nested event loops. Jupyter is using Tornado which already starts an event loop. Therefore the following patch is required to run this tutorial.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec7fc77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ec7fc77",
    "outputId": "e467c26f-8bd4-4d74-eef2-91ecc44cb280"
   },
   "outputs": [],
   "source": [
    "!pip install nest_asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e9455",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Note</b>\n",
    "    \n",
    "The following environment variables can be used to avoid the logging of **some** Tensorflow *DEBUG*, *INFO* and *WARNING* statements.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = str(3)\n",
    "os.environ[\"AUTOGRAPH_VERBOSITY\"] = str(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce038c",
   "metadata": {
    "id": "a8ce038c"
   },
   "source": [
    "## Loading the data\n",
    "\n",
    "First, we will create the `load_data` function which loads and returns the\n",
    "training and validation data. The `load_data` function generates data from\n",
    "a function $f$ where $\\mathbf{x} \\in [a, b]^n$  such as $f(\\mathbf{x}) = -\\sum_{i=0}^{n-1} {x_i ^2}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b5ce3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7b5ce3f",
    "outputId": "d49c6a27-8b12-4430-d7bd-2302992bbe34"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(verbose=0, dim=10, a=-50, b=50, prop=0.80, size=10000):\n",
    "    rs = np.random.RandomState(2018)\n",
    "\n",
    "    def polynome_2(x):\n",
    "        return -sum([x_i ** 2 for x_i in x])\n",
    "\n",
    "    d = b - a\n",
    "    x = np.array([a + rs.random(dim) * d for _ in range(size)])\n",
    "    y = np.array([[polynome_2(v)] for v in x])\n",
    "\n",
    "    sep_index = int(prop * size)\n",
    "    X_train = x[:sep_index]\n",
    "    y_train = y[:sep_index]\n",
    "\n",
    "    X_valid = x[sep_index:]\n",
    "    y_valid = y[sep_index:]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"X_train shape: {np.shape(X_train)}\")\n",
    "        print(f\"y_train shape: {np.shape(y_train)}\")\n",
    "        print(f\"X_valid shape: {np.shape(X_valid)}\")\n",
    "        print(f\"y_valid shape: {np.shape(y_valid)}\")\n",
    "    return (X_train, y_train), (X_valid, y_valid)\n",
    "\n",
    "\n",
    "_ = load_data(verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4a6a0",
   "metadata": {
    "id": "e5f4a6a0"
   },
   "source": [
    "## Define a neural architecture search space\n",
    "\n",
    "Let us define the neural architecture search space. To do this we use a `KSearchSpace` class. We define the `ResNetMLPSpace` search space which is a sub-class of `KSearchSpace` where we have to implement a `build()` method which return itself. The `__init__` method is used to pass possible options of the search space such as the maximum number of layers `self.num_layers`.\n",
    "\n",
    "The input nodes can be retrieved with `self.input_nodes` which is automatically built depending on the `input_shape`.\n",
    "\n",
    "The search space is composed of `ConstantNode` and `VariableNode`. A `ConstantNode` defines a fixed operations whereas the `VariableNode` defines a list of possible operations (i.e., corresponds to a categorical decision variable). Operations can be defined directly from Keras Layers such as:\n",
    "\n",
    "```python\n",
    "Activation = operation(tf.keras.layers.Activation)\n",
    "```\n",
    "\n",
    "All nodes of the search space without outer edges are automatically assumed to be output nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d78fb",
   "metadata": {
    "id": "603d78fb"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from deephyper.nas import KSearchSpace\n",
    "from deephyper.nas.node import ConstantNode, VariableNode\n",
    "from deephyper.nas.operation import operation, Zero, Connect, AddByProjecting, Identity\n",
    "\n",
    "\n",
    "Activation = operation(tf.keras.layers.Activation)\n",
    "Dense = operation(tf.keras.layers.Dense)\n",
    "Dropout = operation(tf.keras.layers.Dropout)\n",
    "Add = operation(tf.keras.layers.Add)\n",
    "Flatten = operation(tf.keras.layers.Flatten)\n",
    "\n",
    "ACTIVATIONS = [\n",
    "    tf.keras.activations.elu,\n",
    "    tf.keras.activations.gelu,\n",
    "    tf.keras.activations.hard_sigmoid,\n",
    "    tf.keras.activations.linear,\n",
    "    tf.keras.activations.relu,\n",
    "    tf.keras.activations.selu,\n",
    "    tf.keras.activations.sigmoid,\n",
    "    tf.keras.activations.softplus,\n",
    "    tf.keras.activations.softsign,\n",
    "    tf.keras.activations.swish,\n",
    "    tf.keras.activations.tanh,\n",
    "]\n",
    "\n",
    "\n",
    "class ResNetMLPSpace(KSearchSpace):\n",
    "    \n",
    "    def __init__(self, input_shape, output_shape, seed=None, num_layers=3, mode=\"regression\"):\n",
    "        super().__init__(input_shape, output_shape, seed=seed)\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        assert mode in [\"regression\", \"classification\"]\n",
    "        self.mode = mode\n",
    "        \n",
    "    def build(self):\n",
    "        \n",
    "        source = self.input_nodes[0]\n",
    "        output_dim = self.output_shape[0]\n",
    "\n",
    "        out_sub_graph = self.build_sub_graph(source, self.num_layers)\n",
    "\n",
    "        if self.mode == \"regression\":\n",
    "            output = ConstantNode(op=Dense(output_dim)) \n",
    "            self.connect(out_sub_graph, output)\n",
    "        else:\n",
    "            output = ConstantNode(\n",
    "                op=Dense(output_dim, activation=\"softmax\")\n",
    "            )  # One-hot encoding\n",
    "            self.connect(out_sub_graph, output)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def build_sub_graph(self, input_, num_layers=3):\n",
    "        source = prev_input = input_\n",
    "\n",
    "        # look over skip connections within a range of the 3 previous nodes\n",
    "        anchor_points = collections.deque([source], maxlen=3)\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            dense = VariableNode()\n",
    "            self.add_dense_to_(dense)\n",
    "            self.connect(prev_input, dense)\n",
    "            x = dense\n",
    "\n",
    "            dropout = VariableNode()\n",
    "            self.add_dropout_to_(dropout)\n",
    "            self.connect(x, dropout)\n",
    "            x = dropout\n",
    "\n",
    "            add = ConstantNode()\n",
    "            add.set_op(AddByProjecting(self, [x], activation=\"relu\"))\n",
    "\n",
    "            for anchor in anchor_points:\n",
    "                skipco = VariableNode()\n",
    "                skipco.add_op(Zero())\n",
    "                skipco.add_op(Connect(self, anchor))\n",
    "                self.connect(skipco, add)\n",
    "\n",
    "            prev_input = add\n",
    "\n",
    "            # ! for next iter\n",
    "            anchor_points.append(prev_input)\n",
    "\n",
    "        return prev_input\n",
    "\n",
    "    def add_dense_to_(self, node):\n",
    "        node.add_op(Identity())  # we do not want to create a layer in this case\n",
    "        for units in range(16, 16 * 16 + 1, 16):\n",
    "            for activation in ACTIVATIONS:\n",
    "                node.add_op(Dense(units=units, activation=activation))\n",
    "\n",
    "    def add_dropout_to_(self, node):\n",
    "        a, b = 1e-3, 0.4\n",
    "        node.add_op(Identity())\n",
    "        dropout_range = np.exp(np.linspace(np.log(a), np.log(b), 10))  #! NAS\n",
    "        for rate in dropout_range:\n",
    "            node.add_op(Dropout(rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5eea4f",
   "metadata": {
    "id": "ad5eea4f"
   },
   "source": [
    "A `KSearchSpace` as some useful methods such as:\n",
    "\n",
    "* `space.sample(choice)` which returns a random model from the search space if `choice == None` or generate a model corresponding to the choice if not.\n",
    "* `space.choices()` which returns the list of discrete dimensions corresponding to the search space.\n",
    "\n",
    "Let us visualize a few randomly sampled neural architecture from this search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e4147e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "id": "42e4147e",
    "outputId": "f00129ee-bc22-4e6e-a9be-6b042741270d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "shapes = dict(input_shape=(10,), output_shape=(1,))\n",
    "space = ResNetMLPSpace(**shapes).build()\n",
    "\n",
    "print(\"Choices: \", space.choices())\n",
    "\n",
    "images = []\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range(4):\n",
    "    \n",
    "    plt.subplot(2,2,i+1)\n",
    "    model = space.sample()\n",
    "    plot_model(model, \"random_model.png\", \n",
    "               show_shapes=False, show_layer_names=False) \n",
    "    image = mpimg.imread(\"random_model.png\")   \n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25948d79",
   "metadata": {
    "id": "25948d79"
   },
   "source": [
    "## Create a problem instance\n",
    "\n",
    "Let us define the neural architecture search problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be0797a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8be0797a",
    "outputId": "e809405e-b53d-46cf-8a5f-356eb29b91c9"
   },
   "outputs": [],
   "source": [
    "from deephyper.problem import NaProblem\n",
    "from deephyper.nas.preprocessing import minmaxstdscaler\n",
    "\n",
    "# Create a Neural Architecture problem\n",
    "problem = NaProblem()\n",
    "\n",
    "# Link the load-data function\n",
    "problem.load_data(load_data)\n",
    "\n",
    "# The function passed to preprocessing has to return \n",
    "# a scikit-learn like preprocessor.\n",
    "problem.preprocessing(minmaxstdscaler)\n",
    "\n",
    "# Link the defined search space\n",
    "problem.search_space(ResNetMLPSpace)\n",
    "\n",
    "# Fixed hyperparameters for all trained models\n",
    "problem.hyperparameters(\n",
    "    batch_size=32,\n",
    "    learning_rate=0.01,\n",
    "    optimizer=\"adam\",\n",
    "    num_epochs=20,\n",
    "    callbacks=dict(\n",
    "        EarlyStopping=dict(\n",
    "            monitor=\"val_r2\", mode=\"max\", verbose=0, patience=5\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define the optimized loss (it can also be a function)\n",
    "problem.loss(\"mse\")\n",
    "\n",
    "# Define metrics to compute for each training and validation epoch\n",
    "problem.metrics([\"r2\"])\n",
    "\n",
    "# Define the maximised objective\n",
    "problem.objective(\"val_r2__last\")\n",
    "\n",
    "problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b501b3",
   "metadata": {
    "id": "64b501b3"
   },
   "source": [
    "Find more about `NaProblem` settings on the [Problem documentation](https://deephyper.readthedocs.io/en/latest/api/deephyper.problem.html).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Tip</b>\n",
    "    \n",
    "\n",
    "Adding an `EarlyStopping(...)` callback is a good idea to stop the training of your model as soon as it stops to improve.\n",
    "\n",
    "```python\n",
    "...\n",
    "EarlyStopping=dict(monitor=\"val_r2\", mode=\"max\", verbose=0, patience=5)\n",
    "...\n",
    "```\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4ba367",
   "metadata": {
    "id": "8d4ba367"
   },
   "source": [
    "## Running the search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b452fe5b",
   "metadata": {
    "id": "b452fe5b"
   },
   "source": [
    "Create an `Evaluator` object using the `ray` backend to distribute the evaluation of the run-function. In neural architecture search DeepHyper provides the `run_base_trainer` function which automate the training process of a sampled model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f723d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "197f723d",
    "outputId": "f8a945c2-5b22-4f6f-8551-37e80a905593"
   },
   "outputs": [],
   "source": [
    "from deephyper.evaluator import Evaluator\n",
    "from deephyper.evaluator.callback import LoggerCallback\n",
    "from deephyper.nas.run import run_base_trainer\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == \"GPU\"]\n",
    "\n",
    "n_gpus = len(get_available_gpus())\n",
    "if n_gpus > 1:\n",
    "    n_gpus -= 1\n",
    "    \n",
    "is_gpu_available = n_gpus > 0\n",
    "\n",
    "if is_gpu_available:\n",
    "    print(f\"{n_gpus} GPU{'s are' if n_gpus > 1 else ' is'} available.\")\n",
    "else:\n",
    "    print(\"No GPU available\")\n",
    "\n",
    "\n",
    "from deephyper.evaluator import Evaluator\n",
    "from deephyper.evaluator.callback import LoggerCallback\n",
    "\n",
    "\n",
    "def get_evaluator(run_function):\n",
    "    # Default arguments for Ray: 1 worker and 1 worker per evaluation\n",
    "    method_kwargs = {\n",
    "        \"num_cpus\": 1, \n",
    "        \"num_cpus_per_task\": 1,\n",
    "        \"callbacks\": [LoggerCallback()]\n",
    "    }\n",
    "\n",
    "    # If GPU devices are detected then it will create 'n_gpus' workers\n",
    "    # and use 1 worker for each evaluation\n",
    "    if is_gpu_available:\n",
    "        method_kwargs[\"num_cpus\"] = n_gpus\n",
    "        method_kwargs[\"num_gpus\"] = n_gpus\n",
    "        method_kwargs[\"num_cpus_per_task\"] = 1\n",
    "        method_kwargs[\"num_gpus_per_task\"] = 1\n",
    "\n",
    "    evaluator = Evaluator.create(\n",
    "        run_function, \n",
    "        method=\"ray\", \n",
    "        method_kwargs=method_kwargs\n",
    "    )\n",
    "    print(f\"Created new evaluator with {evaluator.num_workers} worker{'s' if evaluator.num_workers > 1 else ''} and config: {method_kwargs}\", )\n",
    "    \n",
    "    return evaluator\n",
    "\n",
    "evaluator_1 = get_evaluator(run_base_trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6cd751",
   "metadata": {
    "id": "1b6cd751"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Tip</b> \n",
    "    \n",
    "If executed locally, you can open the ray-dashboard at an address like <a>http://127.0.0.1:port</a> in a browser to monitor the CPU usage of the execution.\n",
    "    \n",
    "</div>\n",
    "\n",
    "Finally, you can define a Random search called `Random` and link to it the defined `problem` and `evaluator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e09062",
   "metadata": {
    "id": "b2e09062"
   },
   "outputs": [],
   "source": [
    "from deephyper.search.nas import Random\n",
    "\n",
    "\n",
    "search = Random(problem, evaluator_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0892e8a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0892e8a0",
    "outputId": "2314a970-98a2-4b33-c0b5-d108d6272152"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"save/history\"):\n",
    "    histories = [os.path.join(\"save/history\", f) for f in os.listdir(\"save/history/\") if \".json\" in f]\n",
    "    for history in histories:\n",
    "        os.remove(history)\n",
    "\n",
    "results = search.search(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb594125",
   "metadata": {
    "id": "eb594125"
   },
   "source": [
    "After the search is over, you will find the following files in your current folder:\n",
    "\n",
    "```\n",
    "results.csv\n",
    "save/\n",
    "```\n",
    "\n",
    "Let us visualize the training of our models. First, we need to load the training history of each model which are located in `save/history`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ecd2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c99ecd2d",
    "outputId": "3ec536dc-b958-40e9-877d-37af339600dc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "histories = [os.path.join(\"save/history\", f) for f in os.listdir(\"save/history/\") if \".json\" in f]\n",
    "\n",
    "for i, fpath in enumerate(histories):\n",
    "    with open(fpath, \"r\") as fd:\n",
    "        histories[i] = json.load(fd)\n",
    "        \n",
    "print(list(histories[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed3cf4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "0aed3cf4",
    "outputId": "c7732592-d0af-426a-e1e2-a54357307069"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.clf()\n",
    "\n",
    "for h in histories:\n",
    "    plt.plot(h[\"val_r2\"])\n",
    "\n",
    "plt.ylabel(\"Validation $R^2$\")\n",
    "plt.xlabel(\"Epochs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02b4096",
   "metadata": {
    "id": "c02b4096"
   },
   "source": [
    "Once the search is over, a file named `results.csv` is saved in the current directory. The same dataframe is returned by the `search.search(...)` call. It contains the configurations evaluated during the search and their corresponding `objective` value (i.e, validation accuracy), `duration` of computation and time of computation with `elapsed_sec`. Each neural architecture is embedded as a list of discrete decision variables called `arch_seq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e7aed4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "15e7aed4",
    "outputId": "4942cd87-9c3b-4ebb-f8c6-52c79e5b3eb9"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d51e46",
   "metadata": {
    "id": "c6d51e46"
   },
   "source": [
    "The `deephyper-analytics` command line is a way of analyzing this type of file. For example, we want to output the best configuration we can use the `topk` functionnality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da7c6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7da7c6b",
    "outputId": "d7fedf5a-c7bb-4d06-b2db-999fde9dfec3"
   },
   "outputs": [],
   "source": [
    "!deephyper-analytics topk results.csv -k 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20418e5",
   "metadata": {
    "id": "b20418e5"
   },
   "source": [
    "Where each architecture is described as a vector of scalar values named arch_seq. In fact, each of this scalar values represents chosen operations for the variable nodes of our search space. \n",
    "\n",
    "## Testing the best configuration\n",
    "\n",
    "We can visualize the architecture of the best configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c07327",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "72c07327",
    "outputId": "cf385040-ffcc-4835-a446-ae7238e6833c"
   },
   "outputs": [],
   "source": [
    "best_config = results.iloc[results.objective.argmax()][:-2].to_dict()\n",
    "arch_seq = json.loads(best_config[\"arch_seq\"])\n",
    "model = space.sample(arch_seq)\n",
    "plot_model(model, show_shapes=False, show_layer_names=False) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "tutorial_05.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c33774984308773a164e9991715538701a09ddea2391d4c1ef9b39eda340d87d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
