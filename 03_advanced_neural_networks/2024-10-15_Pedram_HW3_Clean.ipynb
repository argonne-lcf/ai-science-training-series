{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below is important as our models get bigger: this is wrapping the pytorch data loaders to put the data onto the GPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Homework Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your homework (part 1) for this week is to try to train the model again but with a different architecture.  Change one or more of the following:\n",
    "\n",
    "- The number of convolutions between downsampling\n",
    "- The number of filters in each layer\n",
    "- The initial \"patchify\" layer\n",
    "- Another hyper-parameter of your choosing\n",
    "\n",
    "\n",
    "And compare your final validation accuracy to the accuracy shown here.  Can you beat the validation accuracy shown?\n",
    "\n",
    "For full credit on the homework, you need to show (via text, or make a plot) the training and validation data sets' performance (loss and accuracy) for all the epochs you train.  You also need to explain, in several sentences, what you changed in the network and why you think it makes a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/python-anaconda-2023.09-el8-x86_64/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/python-anaconda-2023.09-el8-x86_64/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# Downloading and transforming training data with augmentation\n",
    "training_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=v2.Compose([\n",
    "        v2.ToTensor(),\n",
    "        v2.RandomHorizontalFlip(),\n",
    "        v2.RandomResizedCrop(size=32, scale=[0.85, 1.0], antialias=False),\n",
    "        v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Downloading and transforming test data\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=v2.ToTensor()  # Direct transformation to tensor for test data\n",
    ")\n",
    "\n",
    "# Splitting training data into training and validation sets\n",
    "train_size = int(0.8 * len(training_data))\n",
    "val_size = len(training_data) - train_size\n",
    "training_data, validation_data = random_split(\n",
    "    training_data, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(55)  # Ensuring reproducibility\n",
    ")\n",
    "\n",
    "# Defining batch size for data loaders\n",
    "batch_size = 128\n",
    "\n",
    "# Optimizing DataLoader creation for faster loading times\n",
    "train_dataloader = DataLoader(\n",
    "    training_data,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,  # Speeds up data transfer to GPU\n",
    "    shuffle=True,     # Shuffling training data\n",
    "    num_workers=4     # Parallelizing data loading\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,    # No need to shuffle validation data\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/python-anaconda-2023.09-el8-x86_64/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "batch, (X, Y) = next(enumerate(train_dataloader))\n",
    "plt.imshow(X[0].cpu().permute((1,2,0))); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "    # CIFAR-10 is *color* images so 3 layers!\n",
    "    return x.view(-1, 3, 32, 32).to(dev), y.to(dev)\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "\n",
    "train_dataloader = WrappedDataLoader(train_dataloader, preprocess)\n",
    "val_dataloader = WrappedDataLoader(val_dataloader, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class Downsampler(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=2):\n",
    "        super(Downsampler, self).__init__()\n",
    "\n",
    "        self.norm = nn.BatchNorm2d(in_channels)  # Better for conv layers than LayerNorm\n",
    "        self.downsample = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=stride,\n",
    "            stride=stride,\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.downsample(self.norm(inputs))\n",
    "\n",
    "\n",
    "class ConvNextBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ConvNextBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=5, padding=2, groups=in_channels)\n",
    "        self.norm = nn.BatchNorm2d(in_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels, 4 * in_channels, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(4 * in_channels, in_channels, kernel_size=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.norm(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x + inputs  # Residual connection\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_initial_filters, n_stages, blocks_per_stage):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.stem = nn.Conv2d(in_channels=3, out_channels=n_initial_filters, kernel_size=1, stride=1)\n",
    "        self.norm1 = nn.BatchNorm2d(n_initial_filters)\n",
    "\n",
    "        current_n_filters = n_initial_filters\n",
    "        layers = []\n",
    "\n",
    "        for i in range(n_stages):\n",
    "            for _ in range(blocks_per_stage):\n",
    "                layers.append(ConvNextBlock(in_channels=current_n_filters))\n",
    "\n",
    "            if i != n_stages - 1:\n",
    "                layers.append(Downsampler(in_channels=current_n_filters, out_channels=2 * current_n_filters))\n",
    "                current_n_filters *= 2  # Double the number of filters\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(current_n_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(current_n_filters, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.stem(inputs)\n",
    "        x = self.norm1(x)\n",
    "        x = self.layers(x)\n",
    "        x = nn.functional.avg_pool2d(x, kernel_size=x.shape[2:])\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Classifier                               [128, 10]                 --\n",
      "├─Conv2d: 1-1                            [128, 64, 32, 32]         256\n",
      "├─BatchNorm2d: 1-2                       [128, 64, 32, 32]         128\n",
      "├─Sequential: 1-3                        [128, 256, 8, 8]          --\n",
      "│    └─ConvNextBlock: 2-1                [128, 64, 32, 32]         --\n",
      "│    │    └─Conv2d: 3-1                  [128, 64, 32, 32]         1,664\n",
      "│    │    └─BatchNorm2d: 3-2             [128, 64, 32, 32]         128\n",
      "│    │    └─Conv2d: 3-3                  [128, 256, 32, 32]        16,640\n",
      "│    │    └─Conv2d: 3-4                  [128, 64, 32, 32]         16,448\n",
      "│    │    └─Dropout: 3-5                 [128, 64, 32, 32]         --\n",
      "│    └─ConvNextBlock: 2-2                [128, 64, 32, 32]         --\n",
      "│    │    └─Conv2d: 3-6                  [128, 64, 32, 32]         1,664\n",
      "│    │    └─BatchNorm2d: 3-7             [128, 64, 32, 32]         128\n",
      "│    │    └─Conv2d: 3-8                  [128, 256, 32, 32]        16,640\n",
      "│    │    └─Conv2d: 3-9                  [128, 64, 32, 32]         16,448\n",
      "│    │    └─Dropout: 3-10                [128, 64, 32, 32]         --\n",
      "│    └─Downsampler: 2-3                  [128, 128, 16, 16]        --\n",
      "│    │    └─BatchNorm2d: 3-11            [128, 64, 32, 32]         128\n",
      "│    │    └─Conv2d: 3-12                 [128, 128, 16, 16]        32,896\n",
      "│    └─ConvNextBlock: 2-4                [128, 128, 16, 16]        --\n",
      "│    │    └─Conv2d: 3-13                 [128, 128, 16, 16]        3,328\n",
      "│    │    └─BatchNorm2d: 3-14            [128, 128, 16, 16]        256\n",
      "│    │    └─Conv2d: 3-15                 [128, 512, 16, 16]        66,048\n",
      "│    │    └─Conv2d: 3-16                 [128, 128, 16, 16]        65,664\n",
      "│    │    └─Dropout: 3-17                [128, 128, 16, 16]        --\n",
      "│    └─ConvNextBlock: 2-5                [128, 128, 16, 16]        --\n",
      "│    │    └─Conv2d: 3-18                 [128, 128, 16, 16]        3,328\n",
      "│    │    └─BatchNorm2d: 3-19            [128, 128, 16, 16]        256\n",
      "│    │    └─Conv2d: 3-20                 [128, 512, 16, 16]        66,048\n",
      "│    │    └─Conv2d: 3-21                 [128, 128, 16, 16]        65,664\n",
      "│    │    └─Dropout: 3-22                [128, 128, 16, 16]        --\n",
      "│    └─Downsampler: 2-6                  [128, 256, 8, 8]          --\n",
      "│    │    └─BatchNorm2d: 3-23            [128, 128, 16, 16]        256\n",
      "│    │    └─Conv2d: 3-24                 [128, 256, 8, 8]          131,328\n",
      "│    └─ConvNextBlock: 2-7                [128, 256, 8, 8]          --\n",
      "│    │    └─Conv2d: 3-25                 [128, 256, 8, 8]          6,656\n",
      "│    │    └─BatchNorm2d: 3-26            [128, 256, 8, 8]          512\n",
      "│    │    └─Conv2d: 3-27                 [128, 1024, 8, 8]         263,168\n",
      "│    │    └─Conv2d: 3-28                 [128, 256, 8, 8]          262,400\n",
      "│    │    └─Dropout: 3-29                [128, 256, 8, 8]          --\n",
      "│    └─ConvNextBlock: 2-8                [128, 256, 8, 8]          --\n",
      "│    │    └─Conv2d: 3-30                 [128, 256, 8, 8]          6,656\n",
      "│    │    └─BatchNorm2d: 3-31            [128, 256, 8, 8]          512\n",
      "│    │    └─Conv2d: 3-32                 [128, 1024, 8, 8]         263,168\n",
      "│    │    └─Conv2d: 3-33                 [128, 256, 8, 8]          262,400\n",
      "│    │    └─Dropout: 3-34                [128, 256, 8, 8]          --\n",
      "├─Sequential: 1-4                        [128, 10]                 --\n",
      "│    └─Flatten: 2-9                      [128, 256]                --\n",
      "│    └─BatchNorm1d: 2-10                 [128, 256]                512\n",
      "│    └─ReLU: 2-11                        [128, 256]                --\n",
      "│    └─Dropout: 2-12                     [128, 256]                --\n",
      "│    └─Linear: 2-13                      [128, 128]                32,896\n",
      "│    └─ReLU: 2-14                        [128, 128]                --\n",
      "│    └─Dropout: 2-15                     [128, 128]                --\n",
      "│    └─Linear: 2-16                      [128, 10]                 1,290\n",
      "==========================================================================================\n",
      "Total params: 1,605,514\n",
      "Trainable params: 1,605,514\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 28.87\n",
      "==========================================================================================\n",
      "Input size (MB): 1.57\n",
      "Forward/backward pass size (MB): 1929.78\n",
      "Params size (MB): 6.42\n",
      "Estimated Total Size (MB): 1937.78\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = Classifier(64, 3, 2)\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "print(summary(model, input_size=(batch_size, 3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn, val_bar):\n",
    "    # Set the model to evaluation mode - some NN pieces behave differently during training\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader)\n",
    "    num_batches = len(dataloader)\n",
    "    loss, correct = 0, 0\n",
    "\n",
    "    # We can save computation and memory by not calculating gradients here - we aren't optimizing\n",
    "    with torch.no_grad():\n",
    "        # loop over all of the batches\n",
    "        for X, y in dataloader:\n",
    "\n",
    "            pred = model(X)\n",
    "            loss += loss_fn(pred, y).item()\n",
    "            # how many are correct in this batch? Tracking for accuracy\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            val_bar.update()\n",
    "\n",
    "    loss /= num_batches\n",
    "    correct /= (size*batch_size)\n",
    "\n",
    "    accuracy = 100*correct\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader, model, loss_fn, optimizer, progress_bar):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Loop over batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Forward pass: compute predictions and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backward pass: compute gradients and update parameters\n",
    "        optimizer.zero_grad()  # Reset gradients before the backward pass\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        # Update the progress bar\n",
    "        progress_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f95e52ac43f467490660d37de92635e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 1/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71820375f96b42a0a6a654b1a22050bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate (Train) Epoch 1/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40: Train Loss: 1.402, Train Accuracy: 48.415%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75f6f0eac2e4a419d9692f4426a6832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validate Epoch 1/40:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40: Validation Loss: 1.381, Validation Accuracy: 48.655%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24de035440e441fad904328741b010f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 2/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6df97edb30446bae036866fc9eb10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate (Train) Epoch 2/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40: Train Loss: 1.163, Train Accuracy: 57.758%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024db18350814a1185d4a8132f5c50c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validate Epoch 2/40:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40: Validation Loss: 1.162, Validation Accuracy: 57.437%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62c19bce2ad4541a7a911884b603fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 3/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a653f6df8d574c508a3a6c5b6bf9cbdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate (Train) Epoch 3/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40: Train Loss: 1.006, Train Accuracy: 63.770%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a84f0de4934f51a0c3dae8a2851c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validate Epoch 3/40:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40: Validation Loss: 1.019, Validation Accuracy: 62.559%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1630df5a59d44d38d7471d57c1cae96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 4/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585efcd8d79d488caf23f997e309f4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate (Train) Epoch 4/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40: Train Loss: 0.949, Train Accuracy: 66.039%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11fd6bc01284f98b93675e113a95eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validate Epoch 4/40:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40: Validation Loss: 0.957, Validation Accuracy: 64.616%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17075ef2dde544e88adc4579b5864e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 5/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c653b7b3b1420b86987e5011e18687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate (Train) Epoch 5/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40: Train Loss: 0.859, Train Accuracy: 69.594%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5494df7f18e47ef90c71c52eb6dc5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validate Epoch 5/40:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40: Validation Loss: 0.877, Validation Accuracy: 68.374%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227fb238c5714b0ea080a7ce4271dc31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 6/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e468fa3f4884e6c8166f6f80051b7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate (Train) Epoch 6/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40: Train Loss: 0.804, Train Accuracy: 71.610%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135ecdc5ed724352b02989cd7e4f8d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validate Epoch 6/40:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40: Validation Loss: 0.830, Validation Accuracy: 69.699%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca2399650794b63becedeb2f87f8ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 7/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d609084d684a0994b4e976345f693d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate (Train) Epoch 7/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40: Train Loss: 0.787, Train Accuracy: 71.546%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc3c81b3f124d6388f747875bc4aa6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validate Epoch 7/40:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40: Validation Loss: 0.802, Validation Accuracy: 70.303%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab45c9011eb4cb3ae2e3242b9246d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 8/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ef61f21a034550b080ef2eb4c13033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate (Train) Epoch 8/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40: Train Loss: 0.703, Train Accuracy: 74.798%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6d18328f604e52be1276f3d4c4e2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validate Epoch 8/40:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40: Validation Loss: 0.728, Validation Accuracy: 73.339%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8d4c72f4304bb2805315f74a00a399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 9/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ca3228bab045d4a99ca81078afafbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate (Train) Epoch 9/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40: Train Loss: 0.706, Train Accuracy: 75.372%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cf55046ad64c148871d4812112185b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validate Epoch 9/40:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40: Validation Loss: 0.732, Validation Accuracy: 73.447%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcc2416b3e94f28b5e968bcc5e50103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 10/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f677fe551fca4ea2aa526ae5037e9340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate (Train) Epoch 10/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40: Train Loss: 0.655, Train Accuracy: 76.820%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848078536b4b4a3c8b9754265dcf9e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validate Epoch 10/40:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40: Validation Loss: 0.695, Validation Accuracy: 74.634%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb2e74ced5c4c42965210977305d723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 11/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b719cf5fa714494baf930d19d80fbf2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate (Train) Epoch 11/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40: Train Loss: 0.602, Train Accuracy: 79.166%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3c15594250435589599f903c70d89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validate Epoch 11/40:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40: Validation Loss: 0.649, Validation Accuracy: 77.027%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d6bf3a10da49ad9511af605de198b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 12/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61de3984c224696a9215a6a925f5942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate (Train) Epoch 12/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40: Train Loss: 0.594, Train Accuracy: 79.263%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638a012d0f834c5d8f2ea247878c30bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validate Epoch 12/40:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40: Validation Loss: 0.633, Validation Accuracy: 77.265%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b944ee052f0446839bdd4105bbc3256f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 13/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc08793f1444f2094b898dc984935fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluate (Train) Epoch 13/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40: Train Loss: 0.568, Train Accuracy: 80.174%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6552de64e6674cb087c24d395472002e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validate Epoch 13/40:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40: Validation Loss: 0.605, Validation Accuracy: 78.491%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925594625e2b45d397545decda9a29a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 14/40:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the number of epochs\n",
    "epochs = 40  # or any number of epochs you'd like to train for\n",
    "\n",
    "# Store results for plotting or analysis later\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "val_loss = []\n",
    "val_accuracy = []\n",
    "\n",
    "# Training loop across epochs\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    with tqdm(total=len(train_dataloader), position=0, leave=True, desc=f\"Train Epoch {epoch + 1}/{epochs}\") as train_bar:\n",
    "        train_one_epoch(train_dataloader, model, loss_fn, optimizer, train_bar)\n",
    "\n",
    "    # Evaluate on training data\n",
    "    with tqdm(total=len(train_dataloader), position=0, leave=True, desc=f\"Evaluate (Train) Epoch {epoch + 1}/{epochs}\") as train_eval_bar:\n",
    "        train_acc, train_loss_value = evaluate(train_dataloader, model, loss_fn, train_eval_bar)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}: Train Loss: {train_loss_value:.3f}, Train Accuracy: {train_acc:.3f}%\")\n",
    "    train_loss.append(train_loss_value)\n",
    "    train_accuracy.append(train_acc)\n",
    "\n",
    "    # Validation phase\n",
    "    with tqdm(total=len(val_dataloader), position=0, leave=True, desc=f\"Validate Epoch {epoch + 1}/{epochs}\") as val_bar:\n",
    "        val_acc, val_loss_value = evaluate(val_dataloader, model, loss_fn, val_bar)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}: Validation Loss: {val_loss_value:.3f}, Validation Accuracy: {val_acc:.3f}%\")\n",
    "    val_loss.append(val_loss_value)\n",
    "    val_accuracy.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# After training and validation loops\n",
    "plt.figure(figsize=(10, 5))  # Optional: set figure size\n",
    "plt.plot(train_accuracy, label='Training Accuracy', marker='o')  # Optional: add marker\n",
    "plt.plot(val_accuracy, label='Validation Accuracy', marker='o')  # Optional: add marker\n",
    "plt.title('Accuracy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.ylim(0, 100)  # Set y-axis limits to percentage\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optional: add a grid for better readability\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# After training and validation loops\n",
    "plt.figure(figsize=(10, 5))  # Optional: set figure size\n",
    "plt.plot(train_loss, label='Training Loss', marker='o')  # Optional: add marker\n",
    "plt.plot(val_loss, label='Validation Loss', marker='o')  # Optional: add marker\n",
    "plt.title('Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, max(max(train_loss), max(val_loss)) * 1.1)  # Adjust y-axis limit if needed\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optional: add a grid for better readability\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making some adjustments to the model, we achieved a validation accuracy of about 80%. Here’s what I changed:\n",
    "\n",
    "* Introduced an additional nn.Conv2d layer (layer 4).\n",
    "* Increased the number of dense layers.\n",
    "* Decreased the filter (kernel) size from 7 to 5, allowing the model to better capture finer details in the images.\n",
    "\n",
    "Initially, the model was experiencing overfitting, with training accuracy exceeding 90% while validation accuracy fell below 80%. To combat this, I implemented DropOut layers between the dense layers and raised the weight decay parameter to strengthen the impact of L2 Regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Other Points Regarding Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  pin_memory=True: Ensures faster transfer of batches from CPU to GPU by pinning memory.\n",
    "2.\tnum_workers=4: Leverages multiple CPU cores to load data in parallel for faster data loading.\n",
    "3.\tRandom Split Efficiency: Calculated the sizes of training and validation datasets explicitly.\n",
    "4.\tReproducibility: Used manual_seed for splitting the dataset to ensure the same split every time.\n",
    "5.\tCode Clarity: Grouped import statements and added comments for easier readability.\n",
    "6. Instead of passing shape (which can be inferred during runtime), we can use nn.GroupNorm or nn.BatchNorm2d in place of LayerNorm, as these are generally better suited for convolutional layers.\n",
    "7. Letting PyTorch manage the shape dynamically makes the code simpler and avoids hardcoding dimensions.\n",
    "8. Use functions from torch.nn.functional where possible to enhance flexibility (e.g., activation functions and padding).\n",
    "9. \tSwitched to BatchNorm2d for spatial data, as it’s better suited for convolutions.\n",
    "10. Removed shape tracking: This reduces complexity, as shapes can be handled dynamically during the forward pass.\n",
    "11. Used nn.functional where applicable for non-learnable operations like avg_pool2d.\n",
    "12. Using .sum() without the need to cast to float, which is more efficient.\n",
    "13. Passed batch_size explicitly instead of relying on a global variable.\n",
    "14. Moved optimizer.zero_grad() before loss.backward(). This is generally the preferred order to ensure gradients are cleared before computing the new ones.\n",
    "15. Changed j to epoch for better readability, and updated the range to start indexing from 1 for clarity during printing.\n",
    "16. Updated the desc parameter in tqdm to provide more meaningful epoch progress descriptions, making it clear which phase (training or validation) is running and the total number of epochs.\n",
    "17. Lists train_loss, train_accuracy, val_loss, and val_accuracy are updated consistently for both phases, ensuring correct storage for further analysis or visualization.\n",
    "18. position=0 and leave=True ensure proper display of progress bars without overlapping or disappearing.\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
