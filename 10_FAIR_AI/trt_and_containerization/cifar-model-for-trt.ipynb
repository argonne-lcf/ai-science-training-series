{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d760d8e",
   "metadata": {},
   "source": [
    "# Classification- CIFAR10\n",
    "\n",
    "We will be using a standard neural network to do classification on the CIFAR-10 dataset. Once we have done so, we will see how to run this network on a container in ThetaG, and then how to optimize inference using this network using NVIDIA TensorRT. The code below closely follows https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ffc4c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c3773",
   "metadata": {},
   "source": [
    "The dataset has already been downloaded and placed in the ____ directory. It was downloaded by running the\n",
    "download_data.py script (to use this script, run it from your terminal: python3 download_data.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e6236",
   "metadata": {},
   "source": [
    "We now define the train and test data loaders, and define some transformations to pre-process the images. Then, we display some of the training images to get an idea of how the data looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f791892",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411364a0",
   "metadata": {},
   "source": [
    "# Model \n",
    "\n",
    "Now that we have taken care of the dataset, we can define our neural network as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad8b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478d9764",
   "metadata": {},
   "source": [
    "We use cross-entropy loss, and use the SGD optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a8f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fa9d21",
   "metadata": {},
   "source": [
    "We can now train the network, printing out the loss every (say) 2000 mini-batches. We then save the model so that we can use it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9baa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca51c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net_10_epochs.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d5294d",
   "metadata": {},
   "source": [
    "Now, we display some images from the test set along with their ground-truth labels. We then load the trained model, and ask the model to classify those very images, and see how these predictions compare with the actual ground-truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea141195",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('Ground Truth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b418f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load('./cifar_net_10_epochs.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ee710",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b914a628",
   "metadata": {},
   "source": [
    "In order to properly evaluate our model, let's run it on the entire test set, and take a look at the accuracy. We also measure the time taken to make predictions for the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74db9c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "net.eval()\n",
    "start_time = time.time()\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "end_time = time.time()\n",
    "\n",
    "print(end_time-start_time)\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8e2643",
   "metadata": {},
   "source": [
    "The model's accuracy is 63%. Remember that this is a 10-way classification task- if the model had guessed randomly, it would've had only 10% accuracy. Therefore, it looks like the model has learnt some useful information about our images. See this link for the state-of-the-art accuracy on CIFAR-10: https://paperswithcode.com/sota/image-classification-on-cifar-10\n",
    "\n",
    "We also note that it takes around 12 seconds. Let's now try to optimize the inference time for this model. We will then look the utility of containers, and run our model using a container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcca8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(4, 3, 32, 32)\n",
    "torch_out = net(dummy_input)\n",
    "input_names = [ \"actual_input\" ]\n",
    "output_names = [ \"output\" ]\n",
    "\n",
    "torch.onnx.export(net, \n",
    "                  dummy_input,\n",
    "                  \"cifar_net_10_epochs.onnx\",\n",
    "                  verbose=False,\n",
    "                  input_names=input_names,\n",
    "                  output_names=output_names,\n",
    "                  export_params=True,\n",
    "                  )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda/2021-11-30",
   "language": "python",
   "name": "conda-2021-11-30"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
