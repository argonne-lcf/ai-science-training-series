{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9774cc5b-bc85-427d-aef7-5c8e8f42e915",
   "metadata": {},
   "source": [
    "# Building a multi-agent system for Computational Chemistry\n",
    "\n",
    "This notebook demonstrates how to build a **ReAct-style agent** using:\n",
    "\n",
    "- **LangGraph**\n",
    "- **ALCF Inference Endpoint** (via `ChatOpenAI`)\n",
    "- Three domain-specific tools:\n",
    "  - `molecule_name_to_smiles`\n",
    "  - `smiles_to_coordinate_file`\n",
    "  - `run_mace_calculation`\n",
    "\n",
    "The agent can:\n",
    "1. Take a molecule name.\n",
    "2. Convert it to a SMILES string.\n",
    "3. Generate a coordinate file from the SMILES.\n",
    "4. Run a MACE-based calculation on the structure.\n",
    "\n",
    "> ⚠️ **Note:** Sometimes the agent may skip tool calls and answer from its internal knowledge. This is expected behavior in ReAct-style agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6da2571-3414-4af2-b921-a599caef57b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from inference_auth_token import get_access_token\n",
    "\n",
    "from tools import molecule_name_to_smiles, smiles_to_coordinate_file, run_mace_calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd317c-dbde-4ded-b765-4bc357ccc223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. State definition\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # LangGraph will automatically append/merge messages using add_messages\n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7cf592-ba27-4d9b-bab0-276300668726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. Routing logic\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "def route_tools(state: State):\n",
    "    \"\"\"Route to the 'tools' node if the last message has tool calls; otherwise, route to 'done'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state : State\n",
    "        The current state containing messages and remaining steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Either 'tools' or 'done' based on the state conditions\n",
    "    \"\"\"\n",
    "    # The state may sometimes be a list of messages; handle that case\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "\n",
    "    # If the last AI message has tool_calls, route to the tools node\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return \"done\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9054a7a-8414-4b71-b2c6-1e8031151a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. LLM node: the \"agent\"\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "def chem_agent(\n",
    "    state: State,\n",
    "    llm: ChatOpenAI,\n",
    "    tools: list,\n",
    "    system_prompt: str = \"You are an assistant that use tools to solve problems \",\n",
    "):\n",
    "    # In this simple example, we wrap the entire message state as a user message.\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"{state['messages']}\"},\n",
    "    ]\n",
    "\n",
    "    # Bind tools to the LLM so it can decide to call them\n",
    "    llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "    # Invoke the LLM and return the updated messages\n",
    "    return {\"messages\": [llm_with_tools.invoke(messages)]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af4e281-19e4-4098-89a8-aa5c7dfbce62",
   "metadata": {},
   "source": [
    "## Second LLM Node – `structured_output_agent`\n",
    "\n",
    "Once tools have finished (or if no tools were needed), we hand the state to a\n",
    "**second agent** whose only job is to produce **JSON-only output**.\n",
    "\n",
    "This is useful for downstream consumption (e.g., other scripts, dashboards, or pipelines).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aafa9c-85a3-4372-8b4a-9cd47b7073e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3*. A second agent: Handle creating structured output\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "def structured_output_agent(\n",
    "    state: State,\n",
    "    llm: ChatOpenAI,\n",
    "    system_prompt: str = (\"You are an assistant that returns ONLY JSON. \"),\n",
    "):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"{state['messages']}\"},\n",
    "    ]\n",
    "\n",
    "    result = llm.invoke(messages)\n",
    "    return {\"messages\": [result]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc608002-8273-4a98-a636-f059a78eb985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. LLM / tools setup\n",
    "# ============================================================\n",
    "\n",
    "# Get token for your ALCF inference endpoint\n",
    "access_token = get_access_token()\n",
    "\n",
    "# Initialize the model hosted on the ALCF endpoint\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"openai/gpt-oss-20b\",\n",
    "    # model_name=\"Qwen/Qwen3-32B\",\n",
    "    api_key=access_token,\n",
    "    base_url=\"https://data-portal-dev.cels.anl.gov/resource_server/sophia/vllm/v1\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Tool list that the LLM can call\n",
    "tools = [molecule_name_to_smiles, smiles_to_coordinate_file, run_mace_calculation]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74caa18-046d-4ed5-ac29-efec9f89e6fa",
   "metadata": {},
   "source": [
    "## Build the LangGraph\n",
    "\n",
    "We build a `StateGraph` with the following nodes:\n",
    "\n",
    "- `\"chem_agent\"` – decides whether tools are needed.\n",
    "- `\"tools\"` – executes any requested tools.\n",
    "- `\"structured_output_agent\"` – converts everything into final JSON.\n",
    "\n",
    "**Flow:**\n",
    "\n",
    "1. `START` → `chem_agent`\n",
    "2. After `chem_agent`:\n",
    "   - If it requested tools → `\"tools\"` → back to `\"chem_agent\"`\n",
    "   - If no tools needed → `\"structured_output_agent\"` → `END`\n",
    "python\n",
    "Copy code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a01f88c-f124-4086-ba4d-4d3d5a7c3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. Build the graph\n",
    "# ============================================================\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Agent node: calls LLM, which may decide to call tools\n",
    "graph_builder.add_node(\n",
    "    \"chem_agent\",\n",
    "    lambda state: chem_agent(state, llm=llm, tools=tools),\n",
    ")\n",
    "graph_builder.add_node(\n",
    "    \"structured_output_agent\",\n",
    "    lambda state: structured_output_agent(state, llm=llm),\n",
    ")\n",
    "\n",
    "# Tool node: executes tool calls emitted by the LLM\n",
    "tool_node = ToolNode(tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Graph logic\n",
    "# START -> chem_agent\n",
    "graph_builder.add_edge(START, \"chem_agent\")\n",
    "\n",
    "# After chem_agent runs, check if we need to run tools\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chem_agent\", route_tools, {\"tools\": \"tools\", \"done\": \"structured_output_agent\"}\n",
    ")\n",
    "\n",
    "# After tools run, go back to the agent so it can use tool results\n",
    "graph_builder.add_edge(\"tools\", \"chem_agent\")\n",
    "\n",
    "# After structured_output_agent, terminate the graph\n",
    "graph_builder.add_edge(\"structured_output_agent\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b0ebe-fb24-4ff5-a6f5-22e00b19ae5c",
   "metadata": {},
   "source": [
    "## Visualize the graph\n",
    "\n",
    "You can visualize the graph using draw_ascii() method, or draw_mermaid_png()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a64499ce-ba34-4aae-8e3e-7aaaaca40bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            +-----------+                     \n",
      "            | __start__ |                     \n",
      "            +-----------+                     \n",
      "                  *                           \n",
      "                  *                           \n",
      "                  *                           \n",
      "           +------------+                     \n",
      "           | chem_agent |                     \n",
      "           +------------+                     \n",
      "           **           ..                    \n",
      "         **               ..                  \n",
      "       **                   ..                \n",
      "+-------+         +-------------------------+ \n",
      "| tools |         | structured_output_agent | \n",
      "+-------+         +-------------------------+ \n",
      "                                *             \n",
      "                                *             \n",
      "                                *             \n",
      "                          +---------+         \n",
      "                          | __end__ |         \n",
      "                          +---------+         \n"
     ]
    }
   ],
   "source": [
    "print(graph.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5eb94c-7319-4c4d-9539-8ba992c7f3ed",
   "metadata": {},
   "source": [
    "## Run the Graph – Example Prompt\n",
    "\n",
    "Now we can **stream** the graph execution for a chemistry task:\n",
    "\n",
    "> “Optimize formic acid and acetic acid with MACE. Return the results in a JSON.”\n",
    "\n",
    "As the graph runs, we print the **latest message** at each step.  \n",
    "Depending on the model and tools, you should see:\n",
    "\n",
    "- Tool calls to MACE for each molecule.\n",
    "- Final JSON-style result from the `structured_output_agent`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e6d7234-37af-4337-a56b-514ed75893ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Optimize formic acid and acetic acid with MACE. Return the results in a JSON.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  molecule_name_to_smiles (chatcmpl-tool-e1a2cd214dc74bd69dd1299891659a81)\n",
      " Call ID: chatcmpl-tool-e1a2cd214dc74bd69dd1299891659a81\n",
      "  Args:\n",
      "    name: formic acid\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: molecule_name_to_smiles\n",
      "\n",
      "C(=O)O\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  molecule_name_to_smiles (chatcmpl-tool-0b221f37a38b40dd8f76aefeaefc7f4a)\n",
      " Call ID: chatcmpl-tool-0b221f37a38b40dd8f76aefeaefc7f4a\n",
      "  Args:\n",
      "    name: acetic acid\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: molecule_name_to_smiles\n",
      "\n",
      "CC(=O)O\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  smiles_to_coordinate_file (chatcmpl-tool-6c3b1b7997cd45339e21da88947a3500)\n",
      " Call ID: chatcmpl-tool-6c3b1b7997cd45339e21da88947a3500\n",
      "  Args:\n",
      "    smiles: C(=O)O\n",
      "    output_file: formic.xyz\n",
      "    randomSeed: 2025\n",
      "    fmt: xyz\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: smiles_to_coordinate_file\n",
      "\n",
      "{\"ok\": true, \"artifact\": \"coordinate_file\", \"path\": \"/lus/grand/projects/IQC/thang/ALCF_contributions/ai-science-training-series/04-Inference-Workflows/Agentic-workflows/formic.xyz\", \"smiles\": \"C(=O)O\", \"natoms\": 5}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  smiles_to_coordinate_file (chatcmpl-tool-daf77ea72622493e93886a6709938e88)\n",
      " Call ID: chatcmpl-tool-daf77ea72622493e93886a6709938e88\n",
      "  Args:\n",
      "    smiles: CC(=O)O\n",
      "    output_file: acetic.xyz\n",
      "    randomSeed: 2025\n",
      "    fmt: xyz\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: smiles_to_coordinate_file\n",
      "\n",
      "{\"ok\": true, \"artifact\": \"coordinate_file\", \"path\": \"/lus/grand/projects/IQC/thang/ALCF_contributions/ai-science-training-series/04-Inference-Workflows/Agentic-workflows/acetic.xyz\", \"smiles\": \"CC(=O)O\", \"natoms\": 8}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  run_mace_calculation (chatcmpl-tool-d7dbe49b40b84be6812456ad26d20b17)\n",
      " Call ID: chatcmpl-tool-d7dbe49b40b84be6812456ad26d20b17\n",
      "  Args:\n",
      "    input_file: /lus/grand/projects/IQC/thang/ALCF_contributions/ai-science-training-series/04-Inference-Workflows/Agentic-workflows/formic.xyz\n",
      "    mace_model_name: small\n",
      "    device: cpu\n",
      "    optimize: True\n",
      "    fmax: 0.05\n",
      "    max_steps: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lus/eagle/projects/ALCFAITP/04-Inference-Workflows/env/_ai4s_agentic_conda/lib/python3.10/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuequivariance or cuequivariance_torch is not available. Cuequivariance acceleration will be disabled.\n",
      "Using Materials Project MACE for MACECalculator with /home/tdpham2/.cache/mace/20231210mace128L0_energy_epoch249model\n",
      "Using float32 for MACECalculator, which is faster but less accurate. Recommended for MD. Use float64 for geometry optimization.\n",
      "Using head Default out of ['Default']\n",
      "Default dtype float32 does not match model dtype float64, converting models to float32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lus/eagle/projects/ALCFAITP/04-Inference-Workflows/env/_ai4s_agentic_conda/lib/python3.10/site-packages/mace/calculators/mace.py:197: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Step     Time          Energy          fmax\n",
      "BFGS:    0 20:46:01      -29.060833        4.386633\n",
      "BFGS:    1 20:46:01      -29.179813        3.443640\n",
      "BFGS:    2 20:46:01      -29.272917        0.968001\n",
      "BFGS:    3 20:46:01      -29.314631        0.749908\n",
      "BFGS:    4 20:46:01      -29.381224        0.561765\n",
      "BFGS:    5 20:46:01      -29.386503        0.306008\n",
      "BFGS:    6 20:46:01      -29.391729        0.284840\n",
      "BFGS:    7 20:46:01      -29.392881        0.167910\n",
      "BFGS:    8 20:46:01      -29.393208        0.027594\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: run_mace_calculation\n",
      "\n",
      "{\"status\": \"success\", \"message\": \"MACE geometry optimization completed.\", \"mode\": \"geometry_optimization\", \"converged\": true, \"input_file\": \"/lus/grand/projects/IQC/thang/ALCF_contributions/ai-science-training-series/04-Inference-Workflows/Agentic-workflows/formic.xyz\", \"mace_model_name\": \"small\", \"device\": \"cpu\", \"final_energy_eV\": -29.393207550048828, \"final_positions\": [[-0.4298449031878176, 0.028635591103541944, 0.10156060565193815], [-0.5751712559286252, 1.2345633998449237, 0.02884757656756078], [0.7697054204395487, -0.6084524714600533, 0.2398225049874056], [-1.2367918415031856, -0.733552924623932, 0.06758820747612905], [1.472102587728223, 0.07880641969034538, 0.26821451625390585]], \"final_cell\": [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]], \"fmax_used\": 0.05, \"max_steps_used\": 200}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  run_mace_calculation (chatcmpl-tool-fb42e37a7f1f449dad13d72ef1fb78c5)\n",
      " Call ID: chatcmpl-tool-fb42e37a7f1f449dad13d72ef1fb78c5\n",
      "  Args:\n",
      "    input_file: /lus/grand/projects/IQC/thang/ALCF_contributions/ai-science-training-series/04-Inference-Workflows/Agentic-workflows/acetic.xyz\n",
      "    mace_model_name: small\n",
      "    device: cpu\n",
      "    optimize: True\n",
      "    fmax: 0.05\n",
      "    max_steps: 200\n",
      "Using Materials Project MACE for MACECalculator with /home/tdpham2/.cache/mace/20231210mace128L0_energy_epoch249model\n",
      "Using float32 for MACECalculator, which is faster but less accurate. Recommended for MD. Use float64 for geometry optimization.\n",
      "Using head Default out of ['Default']\n",
      "Default dtype float32 does not match model dtype float64, converting models to float32.\n",
      "      Step     Time          Energy          fmax\n",
      "BFGS:    0 20:46:03      -45.989422        2.874368\n",
      "BFGS:    1 20:46:03      -46.095459        1.783374\n",
      "BFGS:    2 20:46:03      -46.144688        0.871162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lus/eagle/projects/ALCFAITP/04-Inference-Workflows/env/_ai4s_agentic_conda/lib/python3.10/site-packages/mace/calculators/mace.py:197: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS:    3 20:46:03      -46.202526        0.791176\n",
      "BFGS:    4 20:46:03      -46.240646        0.873693\n",
      "BFGS:    5 20:46:03      -46.256691        0.522984\n",
      "BFGS:    6 20:46:03      -46.266163        0.219253\n",
      "BFGS:    7 20:46:03      -46.268791        0.139251\n",
      "BFGS:    8 20:46:03      -46.270576        0.116754\n",
      "BFGS:    9 20:46:03      -46.271477        0.070092\n",
      "BFGS:   10 20:46:03      -46.272083        0.069516\n",
      "BFGS:   11 20:46:03      -46.272594        0.070193\n",
      "BFGS:   12 20:46:03      -46.273178        0.078776\n",
      "BFGS:   13 20:46:03      -46.273720        0.077531\n",
      "BFGS:   14 20:46:03      -46.274151        0.057216\n",
      "BFGS:   15 20:46:03      -46.274509        0.073081\n",
      "BFGS:   16 20:46:03      -46.274906        0.077480\n",
      "BFGS:   17 20:46:03      -46.275295        0.055988\n",
      "BFGS:   18 20:46:03      -46.275551        0.043609\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: run_mace_calculation\n",
      "\n",
      "{\"status\": \"success\", \"message\": \"MACE geometry optimization completed.\", \"mode\": \"geometry_optimization\", \"converged\": true, \"input_file\": \"/lus/grand/projects/IQC/thang/ALCF_contributions/ai-science-training-series/04-Inference-Workflows/Agentic-workflows/acetic.xyz\", \"mace_model_name\": \"small\", \"device\": \"cpu\", \"final_energy_eV\": -46.275550842285156, \"final_positions\": [[-0.9719152005586016, -0.12806487596569002, 0.02786943310453597], [0.4575626593253944, 0.3440470332440922, -0.09549310794664233], [0.8433703566670518, 1.479123791949836, -0.34176823291539915], [1.3487294881400513, -0.6809222641981206, 0.14263305385091082], [-1.016610586599709, -1.2060655857595526, -0.16176281165068856], [-1.3107060493166043, 0.07773047249654423, 1.0558603046300161], [-1.604724315030591, 0.4402784093764323, -0.6647001063089151], [2.254293691271075, -0.32612695674273084, 0.03736148313069329]], \"final_cell\": [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]], \"fmax_used\": 0.05, \"max_steps_used\": 200}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"formic_acid\": {\n",
      "    \"smiles\": \"C(=O)O\",\n",
      "    \"final_energy_eV\": -29.393207550048828,\n",
      "    \"final_positions\": [\n",
      "      [-0.4298449031878176, 0.028635591103541944, 0.10156060565193815],\n",
      "      [-0.5751712559286252, 1.2345633998449237, 0.02884757656756078],\n",
      "      [0.7697054204395487, -0.6084524714600533, 0.2398225049874056],\n",
      "      [-1.2367918415031856, -0.733552924623932, 0.06758820747612905],\n",
      "      [1.472102587728223, 0.07880641969034538, 0.26821451625390585]\n",
      "    ],\n",
      "    \"fmax_used\": 0.05,\n",
      "    \"max_steps_used\": 200,\n",
      "    \"converged\": true\n",
      "  },\n",
      "  \"acetic_acid\": {\n",
      "    \"smiles\": \"CC(=O)O\",\n",
      "    \"final_energy_eV\": -46.275550842285156,\n",
      "    \"final_positions\": [\n",
      "      [-0.9719152005586016, -0.12806487596569002, 0.02786943310453597],\n",
      "      [0.4575626593253944, 0.3440470332440922, -0.09549310794664233],\n",
      "      [0.8433703566670518, 1.479123791949836, -0.34176823291539915],\n",
      "      [1.3487294881400513, -0.6809222641981206, 0.14263305385091082],\n",
      "      [-1.016610586599709, -1.2060655857595526, -0.16176281165068856],\n",
      "      [-1.3107060493166043, 0.07773047249654423, 1.0558603046300161],\n",
      "      [-1.604724315030591, 0.4402784093764323, -0.6647001063089151],\n",
      "      [2.254293691271075, -0.32612695674273084, 0.03736148313069329]\n",
      "    ],\n",
      "    \"fmax_used\": 0.05,\n",
      "    \"max_steps_used\": 200,\n",
      "    \"converged\": true\n",
      "  }\n",
      "}\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "{\"formic_acid\":{\"smiles\":\"C(=O)O\",\"final_energy_eV\":-29.393207550048828,\"final_positions\":[[-0.4298449031878176,0.028635591103541944,0.10156060565193815],[-0.5751712559286252,1.2345633998449237,0.02884757656756078],[0.7697054204395487,-0.6084524714600533,0.2398225049874056],[-1.2367918415031856,-0.733552924623932,0.06758820747612905],[1.472102587728223,0.07880641969034538,0.26821451625390585]],\"fmax_used\":0.05,\"max_steps_used\":200,\"converged\":true},\"acetic_acid\":{\"smiles\":\"CC(=O)O\",\"final_energy_eV\":-46.275550842285156,\"final_positions\":[[-0.9719152005586016,-0.12806487596569002,0.02786943310453597],[0.4575626593253944,0.3440470332440922,-0.09549310794664233],[0.8433703566670518,1.479123791949836,-0.34176823291539915],[1.3487294881400513,-0.6809222641981206,0.14263305385091082],[-1.016610586599709,-1.2060655857595526,-0.16176281165068856],[-1.3107060493166043,0.07773047249654423,1.0558603046300161],[-1.604724315030591,0.4402784093764323,-0.6647001063089151],[2.254293691271075,-0.32612695674273084,0.03736148313069329]],\"fmax_used\":0.05,\"max_steps_used\":200,\"converged\":true}}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6. Run / stream the graph\n",
    "# ============================================================\n",
    "\n",
    "prompt = \"Optimize formic acid and acetic acid with MACE. Return the results in a JSON.\"\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": prompt},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    new_message = chunk[\"messages\"][-1]\n",
    "    # pretty_print is a LangChain helper for nicely formatted output\n",
    "    if hasattr(new_message, \"pretty_print\"):\n",
    "        new_message.pretty_print()\n",
    "    else:\n",
    "        # Fallback in case pretty_print is not available\n",
    "        print(new_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6be03-e04c-4254-a92a-fa48aeffd185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
