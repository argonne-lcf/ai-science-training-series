{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "776887de-5e9c-4cd3-9dc4-46771a363135",
   "metadata": {},
   "source": [
    "# Building a ReAct Agent for Computational Chemistry\n",
    "\n",
    "This notebook demonstrates how to build a **ReAct-style agent** using:\n",
    "\n",
    "- **LangGraph**\n",
    "- **ALCF Inference Endpoint** (via `ChatOpenAI`)\n",
    "- Three domain-specific tools:\n",
    "  - `molecule_name_to_smiles`\n",
    "  - `smiles_to_coordinate_file`\n",
    "  - `run_mace_calculation`\n",
    "\n",
    "The agent can:\n",
    "1. Take a molecule name.\n",
    "2. Convert it to a SMILES string.\n",
    "3. Generate a coordinate file from the SMILES.\n",
    "4. Run a MACE-based calculation on the structure.\n",
    "\n",
    "> ⚠️ **Note:** Sometimes the agent may skip tool calls and answer from its internal knowledge. This is expected behavior in ReAct-style agents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ed816-0952-4691-a414-353770ffa0fe",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "\n",
    "In this cell, we import all the Python packages and tools we need:\n",
    "\n",
    "- **TypedDict / Annotated**: Define the graph state schema.\n",
    "- **LangGraph**: Build the agentic workflow as a state machine.\n",
    "- **LangChain OpenAI**: Connect to the ALCF-hosted LLM.\n",
    "- **ToolNode**: Execute tool calls automatically.\n",
    "- **get_access_token**: Helper to authenticate with the ALCF Inference Endpoint.\n",
    "- **tools**: Domain-specific tools for computational chemistry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc13468e-2ddd-4640-a53c-80f52644d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "\n",
    "from langgraph.graph import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from inference_auth_token import get_access_token\n",
    "from tools import (\n",
    "    molecule_name_to_smiles,\n",
    "    smiles_to_coordinate_file,\n",
    "    run_mace_calculation,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17726006-0bfb-4881-8606-3a2e3d718cca",
   "metadata": {},
   "source": [
    "## Define the Graph State\n",
    "\n",
    "LangGraph represents the conversation as a **state**.  \n",
    "In this simple example, our state only has one field:\n",
    "\n",
    "- `messages`: a list of messages that represent the conversation history.\n",
    "\n",
    "We use `Annotated[..., add_messages]` so that LangGraph knows how to **append** new messages as the graph runs.\n",
    "python\n",
    "Copy code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d98bfb13-26d4-40bf-a3fc-2d63f3eb2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # A list of LangChain messages (HumanMessage, AIMessage, ToolMessage, etc.)\n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0d6c68-b4f9-47c1-9501-5c19d8303e4b",
   "metadata": {},
   "source": [
    "## Routing Logic: When Should We Call Tools?\n",
    "\n",
    "After the LLM responds, we need to decide:\n",
    "\n",
    "- Should we send the result to the **tool node** (because the LLM requested tool calls)?\n",
    "- Or are we **done** (no tool calls, just a final answer)?\n",
    "\n",
    "The function `route_tools` looks at the **last AI message** and checks if it has `tool_calls`. If yes, we route to `\"tools\"`. Otherwise, we route to `\"done\"` (which will map to `END` in our graph).\n",
    "python\n",
    "Copy code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49bac108-5ff7-4ecd-a983-235635691171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_tools(state: State) -> str:\n",
    "    \"\"\"Route to the 'tools' node if the last message has tool calls; otherwise, route to 'done'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state : State\n",
    "        The current state containing messages.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Either 'tools' or 'done' based on whether the last AI message requested tool calls.\n",
    "    \"\"\"\n",
    "    # Handle the case where LangGraph might pass a list directly\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to route_tools: {state}\")\n",
    "\n",
    "    # If the AI message contains tool_calls, we route to the tools node\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "\n",
    "    # Otherwise, we are done (no tools to call)\n",
    "    return \"done\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7558b1e-3fac-4669-a7eb-d18a2797b396",
   "metadata": {},
   "source": [
    "## Define the LLM Node: `chem_agent`\n",
    "\n",
    "This node is our **agent**: it\n",
    "\n",
    "1. Takes the current state (conversation history),\n",
    "2. Prepends a **system prompt**,\n",
    "3. Asks the LLM to respond, **binding** the available tools.\n",
    "\n",
    "If the LLM decides that tools are needed, it will output `tool_calls` in its response.  \n",
    "Our routing function from the previous cell will detect that and send control to the `tools` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0942286-6439-4ea0-b9f5-8759f877d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chem_agent(\n",
    "    state: State,\n",
    "    llm: ChatOpenAI,\n",
    "    tools: list,\n",
    "    system_prompt: str = \"You are an assistant that uses tools to solve problems.\",\n",
    "):\n",
    "    \"\"\"Core agent node that calls the LLM with tools enabled.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state : State\n",
    "        Current graph state containing prior messages.\n",
    "    llm : ChatOpenAI\n",
    "        LLM client connected to the ALCF Inference Endpoint.\n",
    "    tools : list\n",
    "        List of tool functions the LLM is allowed to call.\n",
    "    system_prompt : str, optional\n",
    "        System message guiding the agent's behavior.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Updated state with a new AI message appended under 'messages'.\n",
    "    \"\"\"\n",
    "    # Build the message list for the LLM\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        # We pass the full message history as a single user message for simplicity\n",
    "        {\"role\": \"user\", \"content\": f\"{state['messages']}\"},\n",
    "    ]\n",
    "\n",
    "    # Bind tools so the LLM is allowed to call them\n",
    "    llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "    # Invoke the LLM and return the new AI message inside the state\n",
    "    ai_message = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [ai_message]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517a8853-f56c-41f9-b761-c73a93e3becb",
   "metadata": {},
   "source": [
    "## Configure the LLM and Tools\n",
    "\n",
    "Now we:\n",
    "\n",
    "1. Grab an **access token** for the ALCF Inference Endpoint.\n",
    "2. Initialize a `ChatOpenAI` model that points to the ALCF endpoint.\n",
    "3. Define the **tool list** the LLM can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7155ee00-59b9-4da8-b1a6-aaa97afc8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get token for your ALCF inference endpoint\n",
    "access_token = get_access_token()\n",
    "\n",
    "# Initialize the model hosted on the ALCF endpoint\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"openai/gpt-oss-120b\",\n",
    "    api_key=access_token,\n",
    "    base_url=\"https://data-portal-dev.cels.anl.gov/resource_server/sophia/vllm/v1\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Tool list that the LLM can call\n",
    "tools = [molecule_name_to_smiles, smiles_to_coordinate_file, run_mace_calculation]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862644a7-30a1-475e-b022-a6280002543d",
   "metadata": {},
   "source": [
    "## Build the LangGraph State Machine\n",
    "\n",
    "We now use **LangGraph** to build a small state machine:\n",
    "\n",
    "1. `START → chem_agent`\n",
    "2. From `chem_agent`, we decide:\n",
    "   - `tools` if tool calls are present\n",
    "   - `END` if no tools are needed\n",
    "3. After `tools` run, we go back to `chem_agent` so that the LLM can:\n",
    "   - See the tool results\n",
    "   - Decide if more tools are needed\n",
    "   - Or generate a final answer\n",
    "\n",
    "This creates a **loop**:  \n",
    "`chem_agent → tools → chem_agent → ... → END`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4a6e4f-7486-411b-b897-a32b6e55b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Agent node: calls LLM, which may decide to call tools\n",
    "graph_builder.add_node(\n",
    "    \"chem_agent\",\n",
    "    lambda state: chem_agent(state, llm=llm, tools=tools),\n",
    ")\n",
    "\n",
    "# Tool node: executes tool calls emitted by the LLM\n",
    "tool_node = ToolNode(tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Graph logic:\n",
    "# 1. START -> chem_agent\n",
    "graph_builder.add_edge(START, \"chem_agent\")\n",
    "\n",
    "# 2. After chem_agent runs, route based on whether there are tool calls\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chem_agent\",\n",
    "    route_tools,\n",
    "    {\n",
    "        \"tools\": \"tools\",  # go to tools node if tool calls are present\n",
    "        \"done\": END,       # otherwise, end the graph\n",
    "    },\n",
    ")\n",
    "\n",
    "# 3. After tools run, go back to the agent so it can use the tool results\n",
    "graph_builder.add_edge(\"tools\", \"chem_agent\")\n",
    "\n",
    "# Compile the graph into an executable object\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf006ec-6e2e-4336-9729-17b0596c7d02",
   "metadata": {},
   "source": [
    "## Visualize the graph\n",
    "\n",
    "You can visualize the graph using draw_ascii() method, or draw_mermaid_png()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277e39f8-8cfc-405e-8069-1a3a9c4bf3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+         \n",
      "        | __start__ |         \n",
      "        +-----------+         \n",
      "               *              \n",
      "               *              \n",
      "               *              \n",
      "        +------------+        \n",
      "        | chem_agent |        \n",
      "        +------------+        \n",
      "          .         .         \n",
      "        ..           ..       \n",
      "       .               .      \n",
      "+---------+         +-------+ \n",
      "| __end__ |         | tools | \n",
      "+---------+         +-------+ \n"
     ]
    }
   ],
   "source": [
    "print(graph.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d9d57-ccc8-4779-beb1-ff0a0cf45527",
   "metadata": {},
   "source": [
    "## Run and Stream the Graph\n",
    "\n",
    "Finally, we run the graph with a **user prompt** and stream the intermediate states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da31200c-1f04-448c-94aa-288f2217f262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the SMILES string of methanol and the optimized structure of a carbon dioxide molecule?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  molecule_name_to_smiles (chatcmpl-tool-27e260cffa5d46798348810e64fd0340)\n",
      " Call ID: chatcmpl-tool-27e260cffa5d46798348810e64fd0340\n",
      "  Args:\n",
      "    name: methanol\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: molecule_name_to_smiles\n",
      "\n",
      "CO\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  smiles_to_coordinate_file (chatcmpl-tool-e40af4df748a4caca0d3cbdccbb0137e)\n",
      " Call ID: chatcmpl-tool-e40af4df748a4caca0d3cbdccbb0137e\n",
      "  Args:\n",
      "    smiles: O=C=O\n",
      "    output_file: co2.xyz\n",
      "    randomSeed: 2025\n",
      "    fmt: xyz\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: smiles_to_coordinate_file\n",
      "\n",
      "{\"ok\": true, \"artifact\": \"coordinate_file\", \"path\": \"/lus/grand/projects/IQC/thang/ALCF_contributions/ai-science-training-series/04-Inference-Workflows/Agentic-workflows/co2.xyz\", \"smiles\": \"O=C=O\", \"natoms\": 3}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  run_mace_calculation (chatcmpl-tool-5c92e8e7b2fd4249bfc5e52293570ab3)\n",
      " Call ID: chatcmpl-tool-5c92e8e7b2fd4249bfc5e52293570ab3\n",
      "  Args:\n",
      "    input_file: /lus/grand/projects/IQC/thang/ALCF_contributions/ai-science-training-series/04-Inference-Workflows/Agentic-workflows/co2.xyz\n",
      "    mace_model_name: small\n",
      "    device: cpu\n",
      "    optimize: True\n",
      "    fmax: 0.05\n",
      "    max_steps: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lus/eagle/projects/ALCFAITP/04-Inference-Workflows/env/_ai4s_agentic_conda/lib/python3.10/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuequivariance or cuequivariance_torch is not available. Cuequivariance acceleration will be disabled.\n",
      "Using Materials Project MACE for MACECalculator with /home/tdpham2/.cache/mace/20231210mace128L0_energy_epoch249model\n",
      "Using float32 for MACECalculator, which is faster but less accurate. Recommended for MD. Use float64 for geometry optimization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lus/eagle/projects/ALCFAITP/04-Inference-Workflows/env/_ai4s_agentic_conda/lib/python3.10/site-packages/mace/calculators/mace.py:197: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using head Default out of ['Default']\n",
      "Default dtype float32 does not match model dtype float64, converting models to float32.\n",
      "      Step     Time          Energy          fmax\n",
      "BFGS:    0 20:39:53      -22.486820        5.389489\n",
      "BFGS:    1 20:39:53      -22.794083        2.073127\n",
      "BFGS:    2 20:39:53      -22.828390        0.410957\n",
      "BFGS:    3 20:39:53      -22.829935        0.023935\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: run_mace_calculation\n",
      "\n",
      "{\"status\": \"success\", \"message\": \"MACE geometry optimization completed.\", \"mode\": \"geometry_optimization\", \"converged\": true, \"input_file\": \"/lus/grand/projects/IQC/thang/ALCF_contributions/ai-science-training-series/04-Inference-Workflows/Agentic-workflows/co2.xyz\", \"mace_model_name\": \"small\", \"device\": \"cpu\", \"final_energy_eV\": -22.82993507385254, \"final_positions\": [[-1.1782012963728021, -0.017800747019835143, -2.1457061410080795e-22], [1.9271610064685546e-06, -1.9288522034269548e-07, -1.1372469341102953e-22], [1.1781993688828778, 0.017800939871510348, -2.639680559781154e-23]], \"final_cell\": [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]], \"fmax_used\": 0.05, \"max_steps_used\": 200}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**SMILES string for methanol**\n",
      "\n",
      "- **Methanol (CH₃OH)** → `CO`\n",
      "\n",
      "---\n",
      "\n",
      "**Optimized geometry of carbon dioxide (CO₂)**  \n",
      "\n",
      "The CO₂ molecule was built from the SMILES `O=C=O`, converted to a 3‑D XYZ file, and then geometry‑optimized with the MACE “small” model (CPU, BFGS, force convergence = 0.05 eV Å⁻¹, max 200 steps).  \n",
      "\n",
      "- **Final electronic energy:** ‑22.8299 eV  \n",
      "- **Converged:** Yes (maximum force ≈ 0.05 eV Å⁻¹)  \n",
      "\n",
      "**Cartesian coordinates (Å)** (atoms are listed in the order O – C – O as they appear in the XYZ file):\n",
      "\n",
      "| Atom | x (Å) | y (Å) | z (Å) |\n",
      "|------|-------|-------|-------|\n",
      "| O₁   | ‑1.17820130 | ‑0.01780075 | ‑2.15 × 10⁻²² |\n",
      "| C    |   0.00000193 | ‑0.00000019 | ‑1.14 × 10⁻²² |\n",
      "| O₂   |   1.17819937 |   0.01780094 | ‑2.64 × 10⁻²³ |\n",
      "\n",
      "The molecule is essentially linear, with an O–C–O bond length of ≈ 1.178 Å on each side (the tiny offsets are numerical noise from the optimization).\n",
      "\n",
      "**File location**\n",
      "\n",
      "The optimized XYZ file is saved at:\n",
      "\n",
      "```\n",
      "/lus/grand/projects/IQC/thang/ALCF_contributions/ai-science-training-series/04-Inference-Workflows/Agentic-workflows/co2.xyz\n",
      "```\n",
      "\n",
      "You can open this file with any molecular‑visualization program (e.g., VMD, Avogadro, Jmol) to view the 3‑D structure.\n",
      "\n",
      "---\n",
      "\n",
      "**Summary**\n",
      "\n",
      "- Methanol SMILES: `CO`  \n",
      "- CO₂ optimized structure: linear O–C–O with the coordinates above, stored in `co2.xyz`, and a final MACE energy of –22.83 eV.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"What is the SMILES string of methanol and the optimized structure of a carbon dioxide molecule?\"\n",
    ")\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": prompt},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    new_message = chunk[\"messages\"][-1]\n",
    "    # pretty_print() is a LangChain helper to show messages nicely\n",
    "    new_message.pretty_print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
