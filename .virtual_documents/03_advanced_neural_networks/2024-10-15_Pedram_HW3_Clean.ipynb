








import torch
from torch.utils.data import DataLoader, random_split
import torchvision
from torchvision.transforms import v2

# Downloading and transforming training data with augmentation
training_data = torchvision.datasets.CIFAR10(
    root="data",
    train=True,
    download=True,
    transform=v2.Compose([
        v2.ToTensor(),
        v2.RandomHorizontalFlip(),
        v2.RandomResizedCrop(size=32, scale=[0.85, 1.0], antialias=False),
        v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    ])
)

# Downloading and transforming test data
test_data = torchvision.datasets.CIFAR10(
    root="data",
    train=False,
    download=True,
    transform=v2.ToTensor()  # Direct transformation to tensor for test data
)

# Splitting training data into training and validation sets
train_size = int(0.8 * len(training_data))
val_size = len(training_data) - train_size
training_data, validation_data = random_split(
    training_data, [train_size, val_size],
    generator=torch.Generator().manual_seed(55)  # Ensuring reproducibility
)

# Defining batch size for data loaders
batch_size = 128

# Optimizing DataLoader creation for faster loading times
train_dataloader = DataLoader(
    training_data,
    batch_size=batch_size,
    pin_memory=True,  # Speeds up data transfer to GPU
    shuffle=True,     # Shuffling training data
    num_workers=4     # Parallelizing data loading
)

val_dataloader = DataLoader(
    validation_data,
    batch_size=batch_size,
    pin_memory=True,
    shuffle=False,    # No need to shuffle validation data
    num_workers=4
)


from matplotlib import pyplot as plt
%matplotlib inline

batch, (X, Y) = next(enumerate(train_dataloader))
plt.imshow(X[0].cpu().permute((1,2,0))); plt.show()


dev = torch.device(
    "cuda") if torch.cuda.is_available() else torch.device("cpu")


def preprocess(x, y):
    # CIFAR-10 is *color* images so 3 layers!
    return x.view(-1, 3, 32, 32).to(dev), y.to(dev)


class WrappedDataLoader:
    def __init__(self, dl, func):
        self.dl = dl
        self.func = func

    def __len__(self):
        return len(self.dl)

    def __iter__(self):
        for b in self.dl:
            yield (self.func(*b))


train_dataloader = WrappedDataLoader(train_dataloader, preprocess)
val_dataloader = WrappedDataLoader(val_dataloader, preprocess)


from torch import nn
import torch


class Downsampler(nn.Module):
    def __init__(self, in_channels, out_channels, stride=2):
        super(Downsampler, self).__init__()

        self.norm = nn.BatchNorm2d(in_channels)  # Better for conv layers than LayerNorm
        self.downsample = nn.Conv2d(
            in_channels=in_channels,
            out_channels=out_channels,
            kernel_size=stride,
            stride=stride,
        )

    def forward(self, inputs):
        return self.downsample(self.norm(inputs))


class ConvNextBlock(nn.Module):
    def __init__(self, in_channels):
        super(ConvNextBlock, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=5, padding=2, groups=in_channels)
        self.norm = nn.BatchNorm2d(in_channels)
        self.conv2 = nn.Conv2d(in_channels, 4 * in_channels, kernel_size=1)
        self.conv3 = nn.Conv2d(4 * in_channels, in_channels, kernel_size=1)
        self.dropout = nn.Dropout(p=0.5)

    def forward(self, inputs):
        x = self.conv1(inputs)
        x = self.norm(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = nn.functional.gelu(x)
        x = self.dropout(x)
        return x + inputs  # Residual connection


class Classifier(nn.Module):
    def __init__(self, n_initial_filters, n_stages, blocks_per_stage):
        super(Classifier, self).__init__()

        self.stem = nn.Conv2d(in_channels=3, out_channels=n_initial_filters, kernel_size=1, stride=1)
        self.norm1 = nn.BatchNorm2d(n_initial_filters)

        current_n_filters = n_initial_filters
        layers = []

        for i in range(n_stages):
            for _ in range(blocks_per_stage):
                layers.append(ConvNextBlock(in_channels=current_n_filters))

            if i != n_stages - 1:
                layers.append(Downsampler(in_channels=current_n_filters, out_channels=2 * current_n_filters))
                current_n_filters *= 2  # Double the number of filters

        self.layers = nn.Sequential(*layers)

        self.head = nn.Sequential(
            nn.Flatten(),
            nn.BatchNorm1d(current_n_filters),
            nn.ReLU(),
            nn.Dropout(p=0.5),
            nn.Linear(current_n_filters, 128),
            nn.ReLU(),
            nn.Dropout(p=0.5),
            nn.Linear(128, 10)
        )

    def forward(self, inputs):
        x = self.stem(inputs)
        x = self.norm1(x)
        x = self.layers(x)
        x = nn.functional.avg_pool2d(x, kernel_size=x.shape[2:])
        x = self.head(x)
        return x


model = Classifier(64, 3, 2)

model.cuda()

from torchinfo import summary

print(summary(model, input_size=(batch_size, 3, 32, 32)))


def evaluate(dataloader, model, loss_fn, val_bar):
    # Set the model to evaluation mode - some NN pieces behave differently during training
    # Unnecessary in this situation but added for best practices
    model.eval()
    size = len(dataloader)
    num_batches = len(dataloader)
    loss, correct = 0, 0

    # We can save computation and memory by not calculating gradients here - we aren't optimizing
    with torch.no_grad():
        # loop over all of the batches
        for X, y in dataloader:

            pred = model(X)
            loss += loss_fn(pred, y).item()
            # how many are correct in this batch? Tracking for accuracy
            correct += (pred.argmax(1) == y).type(torch.float).sum().item()
            val_bar.update()

    loss /= num_batches
    correct /= (size*batch_size)

    accuracy = 100*correct
    return accuracy, loss


def train_one_epoch(dataloader, model, loss_fn, optimizer, progress_bar):
    # Set model to training mode
    model.train()

    # Loop over batches
    for batch, (X, y) in enumerate(dataloader):
        # Forward pass: compute predictions and loss
        pred = model(X)
        loss = loss_fn(pred, y)

        # Backward pass: compute gradients and update parameters
        optimizer.zero_grad()  # Reset gradients before the backward pass
        loss.backward()  # Compute gradients
        optimizer.step()  # Update model parameters

        # Update the progress bar
        progress_bar.update()


loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)


# Define the number of epochs
epochs = 40  # or any number of epochs you'd like to train for

# Store results for plotting or analysis later
train_loss = []
train_accuracy = []
val_loss = []
val_accuracy = []

# Training loop across epochs
for epoch in range(epochs):
    # Training phase
    with tqdm(total=len(train_dataloader), position=0, leave=True, desc=f"Train Epoch {epoch + 1}/{epochs}") as train_bar:
        train_one_epoch(train_dataloader, model, loss_fn, optimizer, train_bar)

    # Evaluate on training data
    with tqdm(total=len(train_dataloader), position=0, leave=True, desc=f"Evaluate (Train) Epoch {epoch + 1}/{epochs}") as train_eval_bar:
        train_acc, train_loss_value = evaluate(train_dataloader, model, loss_fn, train_eval_bar)

    print(f"Epoch {epoch + 1}/{epochs}: Train Loss: {train_loss_value:.3f}, Train Accuracy: {train_acc:.3f}%")
    train_loss.append(train_loss_value)
    train_accuracy.append(train_acc)

    # Validation phase
    with tqdm(total=len(val_dataloader), position=0, leave=True, desc=f"Validate Epoch {epoch + 1}/{epochs}") as val_bar:
        val_acc, val_loss_value = evaluate(val_dataloader, model, loss_fn, val_bar)

    print(f"Epoch {epoch + 1}/{epochs}: Validation Loss: {val_loss_value:.3f}, Validation Accuracy: {val_acc:.3f}%")
    val_loss.append(val_loss_value)
    val_accuracy.append(val_acc)


import matplotlib.pyplot as plt

# After training and validation loops
plt.figure(figsize=(10, 5))  # Optional: set figure size
plt.plot(train_accuracy, label='Training Accuracy', marker='o')  # Optional: add marker
plt.plot(val_accuracy, label='Validation Accuracy', marker='o')  # Optional: add marker
plt.title('Accuracy per Epoch')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.ylim(0, 100)  # Set y-axis limits to percentage
plt.legend()
plt.grid(True)  # Optional: add a grid for better readability
plt.show()  # Display the plot


import matplotlib.pyplot as plt

# After training and validation loops
plt.figure(figsize=(10, 5))  # Optional: set figure size
plt.plot(train_loss, label='Training Loss', marker='o')  # Optional: add marker
plt.plot(val_loss, label='Validation Loss', marker='o')  # Optional: add marker
plt.title('Loss per Epoch')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim(0, max(max(train_loss), max(val_loss)) * 1.1)  # Adjust y-axis limit if needed
plt.legend()
plt.grid(True)  # Optional: add a grid for better readability
plt.show()  # Display the plot












