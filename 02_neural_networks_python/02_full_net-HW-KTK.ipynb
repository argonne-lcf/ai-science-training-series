{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "662a93d1",
      "metadata": {
        "id": "662a93d1"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e19878bb",
      "metadata": {
        "id": "e19878bb"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "da412dba",
      "metadata": {
        "id": "da412dba",
        "outputId": "811938d1-f5a5-4daf-d2a4-0e24cb20896e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000, 784)\n",
            "\n",
            "MNIST data loaded: train: 60000 test: 10000\n",
            "X_train: (60000, 784)\n",
            "y_train: (60000,)\n"
          ]
        }
      ],
      "source": [
        "# repeating the data prep from the previous notebook\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype(numpy.float32)\n",
        "x_test  = x_test.astype(numpy.float32)\n",
        "\n",
        "x_train /= 255.\n",
        "x_test  /= 255.\n",
        "\n",
        "print(x_train.shape)\n",
        "x_train = x_train.reshape(x_train.shape[0], numpy.prod(x_train[0,:,:].shape))\n",
        "x_test = x_test.reshape(x_test.shape[0], numpy.prod(x_test[0,:,:].shape))\n",
        "\n",
        "print(x_train.shape)\n",
        "y_train = y_train.astype(numpy.int32)\n",
        "y_test  = y_test.astype(numpy.int32)\n",
        "\n",
        "print()\n",
        "print('MNIST data loaded: train:',len(x_train),'test:',len(x_test))\n",
        "print('X_train:', x_train.shape)\n",
        "print('y_train:', y_train.shape)\n",
        "\n",
        "# one-hot encoding:\n",
        "nb_classes = 10\n",
        "y_train_onehot = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
        "y_test_onehot = tf.keras.utils.to_categorical(y_test, nb_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "1kL2RUzFtaqo"
      },
      "id": "1kL2RUzFtaqo",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "EfKucCiotedj",
        "outputId": "ebc0cd1f-853b-4e4a-91b0-38586582ef0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "id": "EfKucCiotedj",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f17d2b36-c47d-4c3c-bb76-0d86469a3865\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f17d2b36-c47d-4c3c-bb76-0d86469a3865\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving layers.py to layers.py\n",
            "Saving layer_utils.py to layer_utils.py\n",
            "Saving fc_net.py to fc_net.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "302994b1",
      "metadata": {
        "id": "302994b1"
      },
      "outputs": [],
      "source": [
        "# Here we import an implementation of a two-layer neural network \n",
        "# this code is based on pieces of the first assignment from Stanford's CSE231n course, \n",
        "# hosted at https://github.com/cs231n/cs231n.github.io with the MIT license\n",
        "from fc_net import TwoLayerNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "4e00e3de",
      "metadata": {
        "id": "4e00e3de"
      },
      "outputs": [],
      "source": [
        "num_features = x_train.shape[1] # this is the number of pixels\n",
        "# The weights are initialized from a normal distribution with standard deviation weight_scale\n",
        "model = TwoLayerNet(input_dim=num_features, hidden_dim=200, num_classes=nb_classes, weight_scale=.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "32f7f1aa",
      "metadata": {
        "id": "32f7f1aa"
      },
      "outputs": [],
      "source": [
        "# here you can take a look if you want at the initial loss from an untrained network\n",
        "loss, gradients = model.loss(x_train, y_train_onehot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "c43e3aa5",
      "metadata": {
        "id": "c43e3aa5"
      },
      "outputs": [],
      "source": [
        "# a simple implementation of stochastic gradient descent\n",
        "def sgd(model, gradients, learning_rate):\n",
        "    for p, w in model.params.items():\n",
        "        dw = gradients[p]\n",
        "        new_weights = w - learning_rate * dw\n",
        "        model.params[p] = new_weights\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "c8316228",
      "metadata": {
        "id": "c8316228"
      },
      "outputs": [],
      "source": [
        "# one training step\n",
        "def learn(model, x_train, y_train_onehot, learning_rate):\n",
        "    loss, gradients = model.loss(x_train, y_train_onehot)\n",
        "    model = sgd(model, gradients, learning_rate)\n",
        "    return loss, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "81886e8c",
      "metadata": {
        "id": "81886e8c"
      },
      "outputs": [],
      "source": [
        "def accuracy(model, x, true_values):\n",
        "    scores = model.loss(x)\n",
        "    predictions = numpy.argmax(scores, axis=1)\n",
        "    N = predictions.shape[0]\n",
        "    acc = (true_values == predictions).sum() / N\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "49754891",
      "metadata": {
        "id": "49754891",
        "outputId": "5a8b8bcf-8249-43dc-ffc1-0a0c5d236bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss 2.18869, accuracy 0.57\n",
            "epoch 1, loss 1.58227, accuracy 0.68\n",
            "epoch 2, loss 0.96213, accuracy 0.79\n",
            "epoch 3, loss 0.71294, accuracy 0.83\n",
            "epoch 4, loss 0.59138, accuracy 0.85\n",
            "epoch 5, loss 0.52907, accuracy 0.87\n",
            "epoch 6, loss 0.51252, accuracy 0.88\n",
            "epoch 7, loss 0.43972, accuracy 0.88\n",
            "epoch 8, loss 0.40520, accuracy 0.89\n",
            "epoch 9, loss 0.38951, accuracy 0.89\n",
            "epoch 10, loss 0.39415, accuracy 0.89\n",
            "epoch 11, loss 0.38445, accuracy 0.90\n",
            "epoch 12, loss 0.35502, accuracy 0.90\n",
            "epoch 13, loss 0.34861, accuracy 0.90\n",
            "epoch 14, loss 0.30564, accuracy 0.90\n",
            "epoch 15, loss 0.31892, accuracy 0.90\n",
            "epoch 16, loss 0.32067, accuracy 0.91\n",
            "epoch 17, loss 0.30100, accuracy 0.91\n",
            "epoch 18, loss 0.31447, accuracy 0.91\n",
            "epoch 19, loss 0.33280, accuracy 0.91\n",
            "epoch 20, loss 0.33023, accuracy 0.91\n",
            "epoch 21, loss 0.33751, accuracy 0.91\n",
            "epoch 22, loss 0.28768, accuracy 0.91\n",
            "epoch 23, loss 0.32150, accuracy 0.92\n",
            "epoch 24, loss 0.30495, accuracy 0.92\n",
            "epoch 25, loss 0.29203, accuracy 0.92\n",
            "epoch 26, loss 0.27577, accuracy 0.92\n",
            "epoch 27, loss 0.26769, accuracy 0.92\n",
            "epoch 28, loss 0.27934, accuracy 0.92\n",
            "epoch 29, loss 0.27118, accuracy 0.92\n",
            "epoch 30, loss 0.27135, accuracy 0.92\n",
            "epoch 31, loss 0.29526, accuracy 0.92\n",
            "epoch 32, loss 0.25086, accuracy 0.92\n",
            "epoch 33, loss 0.28359, accuracy 0.93\n",
            "epoch 34, loss 0.24932, accuracy 0.93\n",
            "epoch 35, loss 0.25749, accuracy 0.93\n",
            "epoch 36, loss 0.27764, accuracy 0.93\n",
            "epoch 37, loss 0.23916, accuracy 0.93\n",
            "epoch 38, loss 0.25199, accuracy 0.93\n",
            "epoch 39, loss 0.23284, accuracy 0.93\n",
            "epoch 40, loss 0.23435, accuracy 0.93\n",
            "epoch 41, loss 0.24555, accuracy 0.93\n",
            "epoch 42, loss 0.25440, accuracy 0.93\n",
            "epoch 43, loss 0.22654, accuracy 0.93\n",
            "epoch 44, loss 0.21827, accuracy 0.93\n",
            "epoch 45, loss 0.24154, accuracy 0.94\n",
            "epoch 46, loss 0.21044, accuracy 0.94\n",
            "epoch 47, loss 0.21948, accuracy 0.94\n",
            "epoch 48, loss 0.24179, accuracy 0.94\n",
            "epoch 49, loss 0.20573, accuracy 0.94\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2ca01c0290>]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3ydZf3/8dcnezdtku6RthQ6gNJBaakgS2hBQAQZishWwK0oVX8Kil+RryJfRLaCIFMEBMqeZZTSvVe6R9omTbN3cv3+OHfSpE2bND3Jndzn/Xw88ui5xznnk7s573Of61zXdZtzDhER6f6i/C5ARETCQ4EuIhIQCnQRkYBQoIuIBIQCXUQkIGL8euLMzEyXnZ3t19OLiHRL8+fPz3fOZbW0zbdAz87OZt68eX49vYhIt2Rmmw60TU0uIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiAREtwv0grJqbntlOZU1dX6XIiLSpXS7QP8kJ5/HPt3IZQ9/Rn5pld/liIh0Gd0u0M8d25/7vj6elbnFXPrQZ5RU1vhdkohIl9DtAh1g+jH9+MeVx7Mhv4yfPLeY+npddUlEpFsGOsCJwzP5xdmjeGvFTp6Zu8XvckREfNdtAx3g6qnZHDconbvfWaMvSUUk4nXrQDczvn/6EewqqeKjtfl+lyMi4qtuHegAJ43IIj0plsdnb/S7FBERX3X7QI+NjuKbk4fwcU4+u0oq/S5HRMQ33T7QAc4b2x/n4NXFuX6XIiLim0AE+og+qRzRO4VPctSOLiKRKxCBDjCybyqLtxZRW1fvdykiIr4ITKCfPqo3+aVVrN1V6ncpIiK+CEygHzeoJwBLthb6XImIiD8CE+jZGUmkJcSweGuR36WIiPgiMIFuZhw7MJ3FW3SGLiKRKTCBDjC6fxprd5VSp8m6RCQCBSrQj+idQnVtPVsKyv0uRUSk0wUq0Ef0TgFQTxcRiUiBCvQjGgO9xOdKREQ6X6ACPTUhlr5pCeTs1Bm6iESeQAU6wOCMJLbuqfC7DBGRThe4QO/XI4HcYgW6iESewAV63x4J7Cyq0nVGRSTiBC7QB6QnUl1Xz7ZCnaWLSGQJXKBPGBKa02WRRoyKSIRpNdDNbJCZvW9mK8xsuZn9oIV9zMzuMbMcM1tiZuM7ptzWDcsMdV3crMFFIhJhYtqwTy3wE+fcAjNLBeab2dvOuRVN9pkOjPB+TgDu9/7tdIlx0STHRVNQVu3H04uI+KbVM3TnXK5zboF3uwRYCQzYZ7fzgcddyGdAupn1C3u1bZSeFEdheY1fTy8i4otDakM3s2xgHDBnn00DgC1Nlreyf+h3ml7JcbpgtIhEnDYHupmlAP8BfuicK27Pk5nZ9WY2z8zm5eXltech2mREnxTWarSoiESYNgW6mcUSCvMnnXMvtLDLNmBQk+WB3rpmnHMPOecmOucmZmVltafeNumblkB+aRXOqS+6iESOtvRyMeDvwErn3F0H2O1l4Aqvt8tkoMg5lxvGOg9Jr+Q4ausdxRW1fpUgItLp2tLLZSrwTWCpmS3y1v0CGAzgnHsAeA04G8gByoGrwl9q22WmxAOwu6yKHkmxfpYiItJpWg1059zHgLWyjwNuCldRh6tXchwAu8uqGdZxLTsiIl1K4EaKwt4z9LySKp8rERHpPIEM9P7pCQBs13wuIhJBAhnoPRJjSYyNJrdIfdFFJHIEMtDNjP7pCTpDF5GIEshAB+idmqA2dBGJKIEN9IyUOHZrgi4RiSCBDfTMlHjyS3WGLiKRI8CBHkdJZS1VtXV+lyIi0ikCG+gZXl90zYsuIpEiuIHujRbNL1Ggi0hkCG6ge2fo+WVqRxeRyBDYQM9M8eZzKdUZuohEhsAGesMZ+m71dBGRCBHYQE+OiyY+Jkp90UUkYgQ20M1MfdFFJKIENtAh1I6erzZ0EYkQgQ70jJR4taGLSMQIdqAnx6mXi4hEjGAHeko8u8uqCF0hT0Qk2AId6JkpcdTUOYora/0uRUSkwwU60DO8wUXq6SIikSDYgZ7cMLhI7egiEnzBDvTG4f86QxeR4At0oKclxAJQUqU2dBEJvkAHenJ8DABlCnQRiQABD/RoAMqrddUiEQm+QAd6fEw0cdFRFFfU+F2KiEiHC3SgAwzqlciG/DK/yxAR6XCBD/QBPZPYWaJeLiISfIEP9PTEWIrK1Q9dRIIv+IGeFEuh2tBFJAIEP9ATYymqqKG+XhN0iUiwBT7QeyTF4RyUaIIuEQm4wAd6emJotOgetaOLSMAFPtDTvEDXGbqIBF3wAz0hNPy/uFJfjIpIsAU+0FO9CbqK1NNFRAIu8IHePz0BgC0F5T5XIiLSsVoNdDP7h5ntMrNlB9h+ipkVmdki7+fX4S+z/dKT4uiZFMtmBbqIBFxMG/Z5DLgXePwg+3zknPtyWCrqAJkp8RSUqZeLiARbq2fozrlZQEEn1NJhMlLidBk6EQm8cLWhTzGzxWb2upmNOdBOZna9mc0zs3l5eXlheurWZaTEk1+mCbpEJNjCEegLgCHOubHAX4GXDrSjc+4h59xE59zErKysMDx122Qm6wxdRILvsAPdOVfsnCv1br8GxJpZ5mFXFkYZKfEUVdRQXVvvdykiIh3msAPdzPqamXm3J3mPuftwHzecMlLiAA3/F5Fga7WXi5k9DZwCZJrZVuA3QCyAc+4B4CLgBjOrBSqAS51zXWpqw4zkeADyS6vok5bgczUiIh2j1UB3zl3WyvZ7CXVr7LIyvTN0taOLSJAFfqQohNrQIXSGLiISVBER6L1TQ4G+s1iBLiLBFRGBnhwfQ0p8DDuLK/0uRUSkw0REoEPo2qKacVFEgixiAr1HogJdRIItYgK9V3IcG/PL/C5DRKTDREygjx2Yzvr8Murru1QXeRGRsImYQE9LDHW5L6+p87kSEZGOETGBnhwfCvSyKl0sWkSCKWICPcUL9FIFuogEVMQEeu/U0BwuuhSdiARVxAT68N7JAGxVoItIQEVMoKcnNkyhq77oIhJMERPocTFRpMTHaE50EQmsiAl08Ib/6wxdRAIqogK9Z1KcztBFJLAiK9CT49hdpkAXkWCKqEAf0iuJDfll1NbpYtEiEjwRFegThvSkpLKWVTtK/C5FRCTsIirQ+6cnAlCoL0ZFJIAiKtB7JMYCUFypQBeR4ImoQE9PCgX6bl0sWkQCKKICPSslnpT4GHJ2lfpdiohI2EVUoEdFGQPSE8kt0sWiRSR4IirQAXqnxbOzRE0uIhI8ERfo6UlxFOti0SISQBEX6D0SYyjQaFERCaCIC/Ty6jqKKmrYvFvzootIsERcoE8elgHA6p0aLSoiwRJxgX7KUVkA7Ciq8LkSEZHwirhAz0yOJzba2K6uiyISMBEX6FFRRt8eCWzbozN0EQmWiAt0gOyMZDbtLvO7DBGRsIrIQO+TlkCeBheJSMBEZKBnJMeRX1aNc87vUkREwiYiA31wRhLVtfVsyFezi4gER0QG+tThmQDM2VDgcyUiIuETkYHet0cCADNeWOpzJSIi4dNqoJvZP8xsl5ktO8B2M7N7zCzHzJaY2fjwlxle8TER+T4mIgHXlmR7DJh2kO3TgRHez/XA/YdfVscyM79LEBEJu1YD3Tk3CzhYY/P5wOMu5DMg3cz6hatAERFpm3C0PQwAtjRZ3uqt24+ZXW9m88xsXl5eXhieuv2O6pMKoK6LIhIYndqY7Jx7yDk30Tk3MSsrqzOfej/nHdcfgAWb9/hah4hIuIQj0LcBg5osD/TWdWmlVbUAXPLgZz5XIiISHuEI9JeBK7zeLpOBIudcbhget0ONHdgDgIyUOJ8rEREJj5jWdjCzp4FTgEwz2wr8BogFcM49ALwGnA3kAOXAVR1VbDhNO7ofcdFRHDMg3e9SRETCotVAd85d1sp2B9wUtoo60QnDepFXonnRRSQYInqETVFFDYu3FrFqR7HfpYiIHLaIDvQlW4sAeGnhdp8rERE5fBEd6HHeFACVNXU+VyIicvgiOtBPH9kbgMc+3ehvISIiYRDRgf7ni8f6XYKISNhEdKAnxcUwbnCo2+KHa/ydikBE5HBFdKADfH3SYAC+9Y/Pqa/XvC4i0n1FfKA3tXpnid8liIi0W8QHesPViwA2F5T7WImIyOGJ+EA/aUQWf/5a6MvRnF2lPlcjItJ+ER/oABdOGEhaQgxPzN7kdykiIu2mQPcUV9ayo7iS9Xk6SxeR7kmBvo+Csmq/SxARaRcF+j40alREuisF+j5eXZKruV1EpFtSoLdge2GF3yWIiBwyBbrnxRtP5IxRfQD48XOLfa5GROTQKdA94wb35MoTswFYtKWQOk0DICLdjAK9iagmR+PjnHz/ChERaQcFehMj+6Y13v7WPz7n7x9vYOHmPT5WJCLSdgr0Jnolx/Holcc3Lv/u1RVccN+nPlYkItJ2CvR9fPHILL9LEBFpFwX6PqKizO8SRETaRYEuIhIQCvQWnDQis9myujCKSHegQG/Bw1dM5KOfndq4/MzczRSWa9IuEenaFOgtSIiNZlCvpMblX764jON++7aPFYmItE6BfhB3Xnis3yWIiLSZAv0gLj5+ULNlXaJORLoyBfohOOOuD9lTVk15da3fpYiI7EeB3orxg9ObLY/73ducf+8nPlUjInJgCvRWPPvtKbz1o5ObrVurphcR6YIU6K2IjY7iyD6pxMU0P1SfrtNsjCLStSjQ22jer85otvz1h+dw1aOfU1tX71NFIiLNKdDbKC0hlle/94Vm695fncfqnSU+VSQi0pwC/RAcPaAHG+84hzNG9W5cd/kjc3ysSERkLwV6O5w6cm+g7ymv4a631/Ds3M1U16r5RUT8o0Bvh8uOH8yJwzMal+95dy0//89SjvzV6zzw4TqKK2t8rE5EIlWbAt3MppnZajPLMbNbWth+pZnlmdki7+fa8JfadURFGbd/5egWt93x+ipu/e9yAHaXVlFRXdeZpYlIBGs10M0sGvgbMB0YDVxmZqNb2PVZ59xx3s8jYa6zyxmWlcLnvzy9xW0F3syME25/hwvv1yXsRKRztOUMfRKQ45xb75yrBp4Bzu/YsrqH1PjYFtd/sDqPu99ZA8CK3OLOLElEIlhbAn0AsKXJ8lZv3b4uNLMlZva8mQ1qYTtmdr2ZzTOzeXl5ee0ot2tJiI3im5OH8Px3pjSbPx3g7nfWNt5euHkPRRU1bMgvI/uWmazYrpAXkfCLCdPjvAI87ZyrMrNvA/8ETtt3J+fcQ8BDABMnTuz2lwEyM353gLb0pi64r3mzy38XbWN0/zTqvSsh6TqmIhIObTlD3wY0PeMe6K1r5Jzb7Zyr8hYfASaEp7zuZZw3kdf/XXpcq/s65xj2i9cY9ovXdIk7EQmLtgT6XGCEmQ01szjgUuDlpjuYWb8mi+cBK8NXYvfxxDUnMOvmUzlpRNZB93tw1nqGznitcXn2ut2UVtW2eb71+ZsKmHj72xRVqHukiOzVaqA752qB7wJvEgrq55xzy83st2Z2nrfb981suZktBr4PXNlRBXdlKfExDM5IoldyHO/+5Ittvl9+aRVH/+ZNzrjrQ8qra1vtx/6Xt9eSX1rNkq2Fh1uyiASIOefPx/2JEye6efPm+fLcnWXJ1kJKq2o5cXgm//PaSh6atb7F/fr3SGB7UWWzdXd89RgS46I599j+zdrYiytrmPaXWWwvquSp607gxOGZHfo7iEjXYmbznXMTW9oWri9FpQXHDtx7cYwZ00dSVlXLk3M277ffvmEOcMsLSwHYUlDO9ScPJy4mCuccx976VuM+MVHNP2B97+mFrMwt5p0ft/3TgYgEhwK9k5gZv7/gGE4YlkHOrlIWbynkwzWtd93801tr+NNbazCDjOT4ZtvKqmv5NCefNTtLuGDcQF5ZvL1xW129IzrKWL69iMTYaIZlpYT9dxKRrkVNLj6pqK6jtKqWX720lDeX7wzrY994ynDu+2AdP582kj++sQqAjXecA8CCzXv41t8/54ObTyEjJf5gDyMiXdDBmlw0OZdPEuOiyUqN51fnjGZE79DZc8O/h+u+D9YBNIZ5U397L4eSqlreWtG+N5FVO4pZsHnPYdXXms83FGjmSpF20Bl6F5N9y8zG2+MHp1PvYNGWw+/NEmVw9dShPPLxhsZ1a38/ndjo5u/pObtKGJ6VgplRW1dPTZ0jMS56v/oazvgPpqCsmnrnyDyETwKrdhQz7e6PuPLEbG49b0yb7ycSKfSlaDdy5YnZpCbEUFJZy6+/PJqa+nqO+tUbh/249Y5mYQ4w4pev87vzx3DWmL6s3lnC1j0VzHhhKUf0TuG354/h8U838cbyHSz8f1+iZ3Jcs/v+fuYKfnH2KMyM6tp6HvhwHdeeNBTn4KFZ63lyzibyS0OTlLUU/p/k5HP0gB70SGw+H05heajLpqZHEDl0OkPvBkoqa3h35S5++OyiDn2exNhoKmr2n+43MyWez2acxitLtvOjZxc3rv/VOaM4PrsXS7YV8f9eWnbAx138mzMZe9tb3HXxWL46fiBlVbWM+c2bTBrai+e+PaXZvvM3FXDh/bMZPzidF26cGr5fTiQgdIbezaUmxPKVcQOYmN2Th2atp7SqlhcWhGZfeP47U3h58XYen73psJ+npTCH0MCn7z61kDeW72i2/vaZbRsQ/NrSXAB+/NxiHv1kY+P8Nwu9tvhl24q47ZXl3HXxcRSUhc7QF2wu5OXF2zkiK4XR/dMAqKqtIz4muoVnCNlVXElKQgxJcfqzlsikM/RuavGWQuZs2M31Jw8nZ1cJ0+7+iD989Rhufn4JF08cyE2nHsH9H6zjmblbWn8wH43pn8banaVU1x34S9D7vzGejJR4Ln5wNo9edTzjB/WkR1KoqWbmklxuemoBP5t2FHe+sZqE2CiOGdCDM0f3paSyhh+feVTj41TW1FFWVUt5dR2DeiVRW1fP1D++x9cmDOKnZx11oKcX6VIOdoauQA8w5xy3/Gcp547tz+V/D13MelJ2L26/4GjyS6uoqXO8u3InJ43I4oZ/zae2G00S9vR1kxk/JL3V7xdmzziN5+Zu5esnDOampxbw+YYCAB64fAJvLt/BiwtDn3Qa2vlzdpUyqFdis08CK3OLeXHhNoZkJHHe2P58vDafqtp6vjJuAP+et4X42GhG9k3lyD6pHfTbNvf+6l3c/uoKXv/BycTFqKNapFGgC1c9+jlJ8TH87evjW9zunGPhlkLuemsN1540lPveX8fnGwv22+/Bb07g20/M7+hywy4lPobSqtoDbp894zRuf3UlM5fmkhwXzaNXTWLS0F5A855HTW2845xm2+77xnimjenb4nTID81ax5/eXMPq26dhtv/2f8/bwtyNBdx50dhWf5epd7zHtsIKPvrZqQzqlbTf9uxbZnLFlCH89vzWp3aW7kf90IVHr5p0wDCH0EjW8YN78q9rT+CUo3pz50XHkuH1bDk+u2fjfmeN6cvDV0zkwvEDm91/2W1ndUzhYXKwMAeY8of3mOm19ZdV13Hxg7P5w+srDxjmANc8NrfZ8o1PLuCHzy5iweY9nPbnD1ixvZjthRVk3zKT/3ltFdV19azaUcJtryznnHs+YsHmPdz68nKqauu4+fklPDdvK0u2FjbOolldW8+zczdT6X23UVtXzwsLttLwftAw7XJpVS0/f34Jn67Lb6ylpe9U9pRVt3KU2ie3qILXvWMn/tIZuhxQfb3j7x9v4NJJgzjm1rc4cXgGT103uXH7+6t2MX5wT1ISYoiOshbDb3hWMuvyyvZbf/XUoXxt4kBW7yjp8N473dHDV0zkd6+uYHNBOQDXnTSUhz/a0Mq94PLJg/nXZ6H5gpp2F/14bX5js1tLffxnr9tNbLSRlRrPkIzkxvVrdpZw5l9m8er3vsDRA3q0+Jyn/ukDNuSXseb26WwrrGDmku3cdOoRLX4SCZerH5vL2IHp/OCMER32HF2VerlIu0RFGdedPAyAeb86g5T45n8up47s3Wz5kSsmkhAbzdED0kiIjSYuOorl24s5996P93vszNQ4RvVLY3mT/uaj+6Xx4y8dyRmj+wCwu7SKmKgo7vswhwc/DM1UmZYQQ3Fl6Gw7KzWeuy85jm88Mofvnz6CG744nFG/Pvw++13BdY83P9lpS5gDjWEO8N6qnXy4Oo8Lxg/knZV7RwY/9ulGbj1vDNf+cx6frsvn6qlDuff9nMbtv/vK0fztvRxevOlE3lwW6tn02tLcxkCftSaPDfllXD55CM45NuSH3rCLK2u45p9zWZ9XxsUTB9ErOY5thRXN3iAabCkop7qunuH7zDH09oqdjBuc3upgtPdW7eK9VbtaDPRdJZWkJcTy3acWcMv0URxxgBHYlTV1VNfVk5bQ8rWBuyMFurRJW0Z7NgRxU6P7p3HtF4Zy3nH9mbk0l8KyGp6dt4W6utAnw7PG9OGNZb259bwxDOzZvD24Ya6ZGdNHMWP6KDbvLqdvj4T9vghseiY6bnA6sVFR+7X/33zWUVw1NZvXlu7g/VW7GptXguzqx0JvCv9sofll9rrdjSHfNMyBxjEFt728gtSEUETc98E6RvVL4/czV7KjODQ76B2vr+K6k4Y23u/pOZsp9pqLzr33Y3YWVzVu23jHOby+NJcbnlzAyL6prNpRAsAbPzyJkX1Dl2O8+p9z+WB1HiN6p/DWj05me1ElGclxJMRGU1BWTVJcNNFRtt/o5qaWbSviy3/9mPOP6887K3dRWlXLM9eHxjrkFlWQHB/TGOCXPDibxVuL2jTqubtQk4t0qqLyGn798jJ+e/7R+40SDafsW2YyqFcif7zwWHolxzGyb1qz7Uu2FnLevZ80Ll82aRDRUcbPp42k3sG5f/2YzQXljB2UzuIthWSmxDWOfDWDP39tLPEx0dz01IJmj3vPZeP412ebqKiuY+m2og77/TpDdJSF7fKIPzrjSP7yzpoWtz1xzSRKKmu58cm9x3LCkJ7M3xQap/CfG07kwvs/5egBaSzbVsxlkwbx9Oeh7rgb/nA2dfUOs1CtD3+0nv99c3Xj44wd2IP/fvcLbN5dzsn/+z5ThmXw9PWT2VJQzkl3vg+E3mwenrWe+NgorpiS3ay2wvJqZq3NJy0hhlOO6s1rS3MprqjhkuMHtdiktLO4kt6p8R3a3KReLhJxiipqiI+JIiH2wAORPlqbxwlDM1rs+tf04/iTczYxeVgGW/dUYMDJR+69xOBP/72Y5+dvBeCbk4c0u2h4ZU0d76zcyXefWrjf4zdM7wCQnhTbOOWBtM/JR2Yxq4XpqBNio6isaT7G4S+XjG024vmBy8fznX+F3kyW3XYWMVHG6X/+kGtPGsojH21gW2EF0PwNLjsjiY27y3nwmxMYkJ5I//REPsnJ53tPL+TGU4bTKzmO22eu5K6Lx1Jb5zhlZBa9UxPC8rsq0EU6UE1dPf/6bBMXTRhIagvtsStzi1m0pZCLJgzk45x8+vVIYNHmQma8uJSXbpzK0Kxkjr31LU4b2ZubTh3O2p2lfLJuN68s3s6dFx7L7PW7eXHhNmKijNp6x7lj+/NpTj67y6o5YWgv5mxo3rz0p6+N5af/Xtxs3Zrbp/PQrHXkFlW2eJEV6Xgv3TSVMf3TWJlb3OziN4dKgS7SxW3ML6Nvj4QWP1HU1zvmbdrT2C8e4MpHP+eD1XnMuvlUnpu3hYsnDmLLnnJmrcljxtmjmjUpXDU1m9+cu7dXy3PztvDqkly+NLoPvVPjeWv5Tm47fwzzN+2hvt6RkhBD37SExvsfzJPXnsBf31vLZ+v3vql8//QR3PPu2sM5HIHV0HT3nxumMGFIr9bv0AIFukjAFJZX8+m63Zx9TL8D7nP1Y3N5b9Uucn4/nZiDfJF4IAs37yGvpIojeqeQV1LF955eyOPXTGJjfjmfrd/N2EE9uGDc3vEIG/PLKK2q5egBPXh58XaemL2Rr44fyNsrdlJX7+iTFs9z80LNU+/+5Ius2F7MoF5JpMRHc8Zdsxof5/2fnsJ3npjP6p0ljOoXOqMNmjsvPJaLjx/Urvsq0EUiUEV1HduLKvbrGuinVTuKObJ3aoujaZu66+013PPuWl7+7tTG5omiihpq6uqZesd7DOiZyAlDM5g8rBc/eCY0juGNH57E5t3lXN+GkcyPXXU8Ly3cxkuLtre6b0e4+ayjuOnUI9p1X/VDF4lAiXHRXSrMgf16Gx3ITacO59Sjspq1NTf0ilp9+/Rm+w7smcRf31vL8KwURvZNY8mtZ1JQWk1majzPfL6Zq6cOZem2Is7/W6hX0+WTB3PyiCxOOar3QQP9J186kszUeKYMy+Dax+eRs6uUJ66ZRE1dfWOX0NvOG8Mlxw9iydYiLn5wNo9ddTxXPhoaQXyg6aj7piWErffQvnSGLiIRYc3OEoorapiYvbftemN+GXExUXy4Jo/Xluby0dp8vnBEJg9dMaHZNMyLthTy8EfrufuS44iNjmJXSSUZyfFEt/BJo2HEdM7vp1NSWcuiLYXc/Pxinrl+MgVlNc2+C2kPNbmIiLRBUXkNiXHRhzWL5furdlFQVs2FEwa2vnM7qMlFRKQNGubZPxz7TonRmTTboohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkI30aKmlkesP+1sdomE8hvdS9/qcbD19Xrg65fY1evD1TjoRrinMtqaYNvgX44zGzegYa+dhWq8fB19fqg69fY1esD1RhOanIREQkIBbqISEB010B/yO8C2kA1Hr6uXh90/Rq7en2gGsOmW7ahi4jI/rrrGbqIiOxDgS4iEhDdLtDNbJqZrTazHDO7xacaBpnZ+2a2wsyWm9kPvPW9zOxtM1vr/dvTW29mdo9X8xIzG9+JtUab2UIze9VbHmpmc7xanjWzOG99vLec423P7qT60s3seTNbZWYrzWxKVzqOZvYj7/94mZk9bWYJfh9DM/uHme0ys2VN1h3yMTOzb3n7rzWzb3VCjf/r/T8vMbMXzSy9ybYZXo2rzeysJus75PXeUn1Ntv3EzJyZZXrLvhzDdnHOdZsfIBpYBwwD4oDFwGgf6ugHjPdupwJrgNHAncAt3lXf6NsAAAP+SURBVPpbgD96t88GXgcMmAzM6cRafww8BbzqLT8HXOrdfgC4wbt9I/CAd/tS4NlOqu+fwLXe7TggvascR2AAsAFIbHLsrvT7GAInA+OBZU3WHdIxA3oB671/e3q3e3ZwjWcCMd7tPzapcbT3Wo4Hhnqv8eiOfL23VJ+3fhDwJqFBj5l+HsN2/V5+Pnk7/hOmAG82WZ4BzOgCdf0X+BKwGujnresHrPZuPwhc1mT/xv06uK6BwLvAacCr3h9kfpMXVePx9P6Ip3i3Y7z9rIPr6+EFpu2zvkscR0KBvsV7wcZ4x/CsrnAMgex9wvKQjhlwGfBgk/XN9uuIGvfZdgHwpHe72eu44Th29Ou9pfqA54GxwEb2Brpvx/BQf7pbk0vDC6zBVm+db7yP1eOAOUAf51yut2kH0Me77VfddwM/A+q95Qyg0DlX20IdjTV624u8/TvSUCAPeNRrFnrEzJLpIsfRObcN+BOwGcgldEzm07WOYYNDPWZ+v5auJnTWy0Fq6dQazex8YJtzbvE+m7pEfW3R3QK9SzGzFOA/wA+dc8VNt7nQW7ZvfULN7MvALufcfL9qaIMYQh9773fOjQPKCDUXNPLzOHrt0OcTeuPpDyQD0/yo5VD4/bfXGjP7JVALPOl3LQ3MLAn4BfBrv2s5HN0t0LcRauNqMNBb1+nMLJZQmD/pnHvBW73TzPp52/sBu7z1ftQ9FTjPzDYCzxBqdvk/IN3MYlqoo7FGb3sPYHcH17gV2Oqcm+MtP08o4LvKcTwD2OCcy3PO1QAvEDquXekYNjjUY+bLa8nMrgS+DHzDe+PpKjUOJ/TGvdh7zQwEFphZ3y5SX5t0t0CfC4zwehnEEfri6eXOLsLMDPg7sNI5d1eTTS8DDd90f4tQ23rD+iu8b8snA0VNPh53COfcDOfcQOdcNqHj9J5z7hvA+8BFB6ixofaLvP079CzPObcD2GJmR3mrTgdW0HWO42Zgspklef/nDfV1mWPYxKEeszeBM82sp/dJ5ExvXYcxs2mEmgDPc86V71P7pV4voaHACOBzOvH17pxb6pzr7ZzL9l4zWwl1fNhBFzqGrfKzAb+dX2ScTahXyTrglz7V8AVCH2mXAIu8n7MJtZe+C6wF3gF6efsb8Dev5qXAxE6u9xT29nIZRujFkgP8G4j31id4yzne9mGdVNtxwDzvWL5EqLdAlzmOwG3AKmAZ8AShnhi+HkPgaUJt+jWEguea9hwzQu3YOd7PVZ1QYw6hNueG18wDTfb/pVfjamB6k/Ud8npvqb59tm9k75eivhzD9vxo6L+ISEB0tyYXERE5AAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQg/j9bJ+p9gx62DQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Here's an example training loop using this two-layer model. Can you do better? \n",
        "learning_rate = 0.1 \n",
        "num_examples = x_train.shape[0]\n",
        "batch_size = 2000\n",
        "num_batches = int(num_examples / batch_size)\n",
        "num_epochs = 50\n",
        "losses = numpy.zeros(num_batches*num_epochs,)\n",
        "indices = numpy.arange(num_examples)\n",
        "\n",
        "i = 0\n",
        "for epoch in range(0, num_epochs):\n",
        "    # in each epoch, we loop over all of the training examples\n",
        "    for step in range(0, num_batches):\n",
        "        # grabbing the next batch\n",
        "        offset = step * batch_size\n",
        "        batch_range = range(offset, offset+batch_size)\n",
        "        x_train_batch = x_train[batch_range, :]\n",
        "        y_train_batch = y_train_onehot[batch_range,:]\n",
        "        \n",
        "        # feed the next batch in to do one sgd step\n",
        "        loss, model = learn(model, x_train_batch, y_train_batch, learning_rate)\n",
        "        losses[i] = loss\n",
        "        i += 1\n",
        "\n",
        "    acc = accuracy(model, x_train, y_train)\n",
        "    print(\"epoch %d, loss %.5f, accuracy %.2f\" % (epoch, loss, acc))\n",
        "    \n",
        "    # reshuffle the data so that we get a new set of batches\n",
        "    numpy.random.shuffle(indices)\n",
        "    x_train = x_train[indices,:]\n",
        "    y_train = y_train[indices] # keep this shuffled the same way for use in accuracy calculation\n",
        "    y_train_onehot = y_train_onehot[indices,:]\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "a4f274c6",
      "metadata": {
        "id": "a4f274c6",
        "outputId": "b80e5f59-1631-4fcc-d539-e2342d2d9939",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9382833333333334"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "accuracy(model, x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2dd5728",
      "metadata": {
        "id": "a2dd5728"
      },
      "source": [
        "# Homework: improve the accuracy of this model. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faaf0515",
      "metadata": {
        "id": "faaf0515"
      },
      "source": [
        "Update this notebook so that the accuracy is improved. How high can you get it? You could change things directly in the notebook, such as increasing the number of epochs, changing the learning weight, changing the width of the hidden layer, etc. If you're more ambitious, you could also try changing the model definition itself by checking out the associated Python files. For example, you could add more layers to the network. The current notebook has a training accuracy of about 43%, but will vary with randomness."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial 1: Increasing the number of epochs from 10 to 50 improved the accurcy from 43% to 65%"
      ],
      "metadata": {
        "id": "mZVKkLap4rhA"
      },
      "id": "mZVKkLap4rhA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial 2: Keeping the epochs at 50 and increasing the learning rate to 0.05 improved the accuracy from 65% for the rate of 0.01 to 87% for the rate of 0.05."
      ],
      "metadata": {
        "id": "PFHyDORq5T7A"
      },
      "id": "PFHyDORq5T7A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial 3: Further, decreasing the batch size from 10000 to 5000, while keeping the epochs at 50 and learning rate at 0.05 the accuracy improved from 87% to 91%."
      ],
      "metadata": {
        "id": "onhsRZpd7CLf"
      },
      "id": "onhsRZpd7CLf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial 4: Further decreasing of the batch size from 5000 to 2000 offered only a moderate improvement in the accuracy from 91% to 93%.\n",
        "\n"
      ],
      "metadata": {
        "id": "doIXpuD_8ZgO"
      },
      "id": "doIXpuD_8ZgO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial 5: Increasing the LR to 0.1 from 0.05 offered further improvement in the accuracy from the previous value of 93% to 96%."
      ],
      "metadata": {
        "id": "wW-xy6219OoE"
      },
      "id": "wW-xy6219OoE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial 6: Further, increasing the number of epochs even more from 50 to 100 improved the accuracy from 96% to 98% but at the cost of increased execution time."
      ],
      "metadata": {
        "id": "lFKbadlz9sUe"
      },
      "id": "lFKbadlz9sUe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial 7: Increasing the width of the hidden layer to 500 (from 300) and going back to 50 epochs, I obtained the accuracy of 94%. Does this mean increasing the hidden layer width does not help very much? I am going to try decreasing the hidden layer width to 200."
      ],
      "metadata": {
        "id": "I9GrwMbx_CsR"
      },
      "id": "I9GrwMbx_CsR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial 8: Decreasing the width of the hidden layer to 200 (from 300) and going back to 50 epochs, I obtained the accuracy of 94%. So it looks like hidden layer width of 300 is somehow optimized for the NN structure. Further work may be required to change the NN structure. More on that later when time permits."
      ],
      "metadata": {
        "id": "Z1ozPvZhC1xh"
      },
      "id": "Z1ozPvZhC1xh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e484c13",
      "metadata": {
        "id": "6e484c13"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}