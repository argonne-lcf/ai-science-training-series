{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19878bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da412dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeating the data prep from the previous notebook\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype(numpy.float32)\n",
    "x_test  = x_test.astype(numpy.float32)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test  /= 255.\n",
    "\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], numpy.prod(x_train[0,:,:].shape))\n",
    "x_test = x_test.reshape(x_test.shape[0], numpy.prod(x_test[0,:,:].shape))\n",
    "\n",
    "print(x_train.shape)\n",
    "y_train = y_train.astype(numpy.int32)\n",
    "y_test  = y_test.astype(numpy.int32)\n",
    "\n",
    "print()\n",
    "print('MNIST data loaded: train:',len(x_train),'test:',len(x_test))\n",
    "print('X_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "\n",
    "# one-hot encoding:\n",
    "nb_classes = 10\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302994b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we import an implementation of a two-layer neural network \n",
    "# this code is based on pieces of the first assignment from Stanford's CSE231n course, \n",
    "# hosted at https://github.com/cs231n/cs231n.github.io with the MIT license\n",
    "from fc_net import TwoLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = x_train.shape[1] # this is the number of pixels\n",
    "# The weights are initialized from a normal distribution with standard deviation weight_scale\n",
    "model = TwoLayerNet(input_dim=num_features, hidden_dim=300, num_classes=nb_classes, weight_scale=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f7f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you can take a look if you want at the initial loss from an untrained network\n",
    "loss, gradients = model.loss(x_train, y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple implementation of stochastic gradient descent\n",
    "def sgd(model, gradients, learning_rate):\n",
    "    for p, w in model.params.items():\n",
    "        dw = gradients[p]\n",
    "        new_weights = w - learning_rate * dw\n",
    "        model.params[p] = new_weights\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8316228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one training step\n",
    "def learn(model, x_train, y_train_onehot, learning_rate):\n",
    "    loss, gradients = model.loss(x_train, y_train_onehot)\n",
    "    model = sgd(model, gradients, learning_rate)\n",
    "    return loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81886e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, true_values):\n",
    "    scores = model.loss(x)\n",
    "    predictions = numpy.argmax(scores, axis=1)\n",
    "    N = predictions.shape[0]\n",
    "    acc = (true_values == predictions).sum() / N\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49754891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's an example training loop using this two-layer model. Can you do better? \n",
    "learning_rate = 0.01  \n",
    "num_examples = x_train.shape[0]\n",
    "batch_size = 10000\n",
    "num_batches = int(num_examples / batch_size)\n",
    "num_epochs = 10\n",
    "losses = numpy.zeros(num_batches*num_epochs,)\n",
    "indices = numpy.arange(num_examples)\n",
    "\n",
    "i = 0\n",
    "for epoch in range(0, num_epochs):\n",
    "    # in each epoch, we loop over all of the training examples\n",
    "    for step in range(0, num_batches):\n",
    "        # grabbing the next batch\n",
    "        offset = step * batch_size\n",
    "        batch_range = range(offset, offset+batch_size)\n",
    "        x_train_batch = x_train[batch_range, :]\n",
    "        y_train_batch = y_train_onehot[batch_range,:]\n",
    "        \n",
    "        # feed the next batch in to do one sgd step\n",
    "        loss, model = learn(model, x_train_batch, y_train_batch, learning_rate)\n",
    "        losses[i] = loss\n",
    "        i += 1\n",
    "\n",
    "    acc = accuracy(model, x_train, y_train)\n",
    "    print(\"epoch %d, loss %.5f, accuracy %.2f\" % (epoch, loss, acc))\n",
    "    \n",
    "    # reshuffle the data so that we get a new set of batches\n",
    "    numpy.random.shuffle(indices)\n",
    "    x_train = x_train[indices,:]\n",
    "    y_train = y_train[indices] # keep this shuffled the same way for use in accuracy calculation\n",
    "    y_train_onehot = y_train_onehot[indices,:]\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f274c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f87bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
